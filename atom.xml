<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Zhiyuan</title>
  
  <subtitle>三尺微命，一介书生</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2019-07-09T13:35:40.419Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Zhiyuan</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>ACL 2019 一些感兴趣的paper</title>
    <link href="http://yoursite.com/2019/07/09/acl_2019/"/>
    <id>http://yoursite.com/2019/07/09/acl_2019/</id>
    <published>2019-07-09T09:17:30.000Z</published>
    <updated>2019-07-09T13:35:40.419Z</updated>
    
    <content type="html"><![CDATA[<p>不久前放出了ACL2019的paper list, 但是还没有具体的文章，这里立一些flag, 找一些感兴趣的paper来读。</p><h2 id="text-style-transfer">Text style transfer</h2><p><strong><em>Towards Fine-grained Text Sentiment Transfer</em></strong> Fuli Luo, Peng Li, Pengcheng Yang, Jie Zhou, Yutong Tan, Baobao Chang, Zhifang Sui and Xu SUN</p><p>这个跟我之前做的问题比较像，比较感兴趣…</p><p><strong><em>A Hierarchical Reinforced Sequence Operation Method for Unsupervised Text Style Transfer</em></strong> Chen Wu, Xuancheng Ren, Fuli Luo and Xu SUN</p><h2 id="open-domain-dialog-system-text-generation">Open-domain Dialog System &amp; Text Generation</h2><h3 id="emotion">Emotion</h3><p><strong><em>Generating Responses with a Specific Emotion in Dialog</em></strong> Zhenqiao Song, Xiaoqing Zheng, Lu Liu, Mu Xu and Xuanjing Huang</p><p>这个很直接的老问题…不知道为什么还被录，可能是效果确实很牛或者模型很新吧..</p><p><strong><em>Towards Empathetic Open-domain Conversation Models: a New Benchmark and Dataset</em></strong> Hannah Rashkin, Eric Michael Smith, Margaret Li and Y-Lan Boureau</p><p>这个像是一个开坑的工作…虽然 Empathetic computing 之前也有一些work, 但是不知道 ACL 为什么今年只有一篇…</p><p><strong><em>Adversarial Attention Modeling for Multi-dimensional Emotion Regression</em></strong> Suyang Zhu, Shoushan Li and Guodong Zhou</p><p>Emotion Regression 可以科普一下</p><p><strong><em>Divide, Conquer and Combine: Hierarchical Feature Fusion Network with Local and Global Perspectives for Multimodal Affective Computing</em></strong> Sijie Mai, Haifeng Hu and Songlong Xing</p><p>Affective Computing的</p><p><strong><em>Entity-Centric Contextual Affective Analysis</em></strong> Anjalie Field and Yulia Tsvetkov</p><p>Affective Computing的</p><h3 id="personalization">Personalization</h3><p><strong><em>Persuasion for Good: Towards a Personalized Persuasive Dialogue System for Social Good</em></strong> Xuewei Wang, Weiyan Shi, Richard Kim, Yoojung Oh, Sijia Yang, Jingwen Zhang and Zhou Yu</p><p>特殊场景？</p><p><strong><em>Personalizing Dialogue Agents via Meta-Learning</em></strong> Andrea Madotto, Zhaojiang Lin, Chien-Sheng Wu and Pascale Fung</p><p>Meta-learning没了解过，通过这个科普一下</p><p><strong><em>Automatic Generation of Personalized Comment Based on User Profile</em></strong> Wenhuan Zeng, Abulikemu Abuduweili, Lei Li and Pengcheng Yang</p><p>可以看一下是如何利用 User Profile 的</p><p><strong><em>Incorporating Textual Information on User Behavior for Personality Prediction</em></strong> Kosuke Yamada, Ryohei Sasano and Koichi Takeda</p><p>关于心理学定义的人格的paper感觉都可以关注一下…</p><h3 id="others">Others</h3><p><strong><em>Semantically Conditioned Dialog Response Generation via Hierarchical Disentangled Self-Attention</em></strong> Wenhu Chen, Jianshu Chen, Pengda Qin, Xifeng Yan and William Yang Wang</p><p>William Yang Wang在微博上推广过这个…</p><p><strong><em>Learning from Dialogue after Deployment: Feed Yourself, Chatbot!</em></strong> Braden Hancock, Antoine Bordes, Pierre-Emmanuel Mazare and Jason Weston</p><p>看标题像是一个online-learning的问题</p><p><strong><em>Dialogue Natural Language Inference</em></strong> Sean Welleck, Jason Weston, Arthur Szlam and Kyunghyun Cho</p><p>这个title, 结合了不知道什么意思</p><p><strong><em>Are Training Samples Correlated? Learning to Generate Dialogue Responses with Multiple References</em></strong> Lisong Qiu, Juntao Li, Wei Bi, Dongyan Zhao and Rui Yan</p><p>看起来像是一个Grounding的问题</p><p><strong><em>Pretraining Methods for Dialog Context Representation Learning</em></strong> Shikib Mehri, Evgeniia Razumovskaia, Tiancheng Zhao and Maxine Eskenazi</p><p>问题很感兴趣，应用场景应该是多轮对话吧</p><p><strong><em>Self-Supervised Dialogue Learning</em></strong> Jiawei Wu, Xin Wang and William Yang Wang</p><p>自监督？</p><p><strong><em>Domain Adaptive Dialog Generation via Meta Learning</em></strong> Kun Qian and Zhou Yu</p><p>每个名词都很感兴趣…</p><p><strong><em>Know More about Each Other: Evolving Dialogue Strategy via Compound Assessment</em></strong> Siqi Bao, Huang He, Fan Wang, Rongzhong Lian and Hua Wu</p><p>关于策略的也很感兴趣，看是如何用其他Knowledge</p><p><strong><em>Do Neural Dialog Systems Use the Conversation History Effectively? An Empirical Study</em></strong> Chinnadhurai Sankar, Sandeep Subramanian, Chris Pal, Sarath Chandar and Yoshua Bengio</p><p>多轮对话？Bengio？</p><p><strong><em>Boosting Dialog Response Generation</em></strong> Wenchao Du and Alan W Black</p><p>Boosting有点意思…</p><p><strong><em>Implicit Discourse Relation Identification for Open-domain Dialogues</em></strong> Mingyu Derek Ma, Kevin Bowden, Jiaqi Wu, Wen Cui and Marilyn Walker</p><p>这个一作好像认识…</p><p><strong><em>ConvLab: Multi-Domain End-to-End Dialog System Platform</em></strong> Sungjin Lee, Qi Zhu, Ryuichi Takanobu, Xiang Li, Yaoqin Zhang, Zheng Zhang, Jinchao Li, Baolin Peng, Xiujun Li, Minlie Huang and Jianfeng Gao</p><p>感兴趣 Multi-Domain</p><p><strong><em>ADVISER: A Dialog System Framework for Education &amp; Research Daniel Ortega, Dirk Väth, Gianna Weber, Lindsey Vanderlyn, Maximilian</em></strong> Schmidt, Moritz Völkel, Zorica Karacevic and Ngoc Thang Vu</p><p>特定应用场景</p><p><strong><em>Dialogue-Act Prediction of Future Responses based on Conversation History</em></strong> Koji Tanaka, Junya Takayama and Yuki Arase</p><p>Prediction 感兴趣</p><p><strong><em>Vocabulary Pyramid Network: Multi-Pass Encoding and Decoding with Multi-Level Vocabularies for Response Generation</em></strong> Cao Liu, Shizhu He, Kang Liu and Jun Zhao</p><p>刘康老师的work呀</p><p><strong><em>Learning to Abstract for Memory-augmented Conversational Response Generation</em></strong> Zhiliang Tian, Wei Bi, Xiaopeng Li and Nevin L. Zhang</p><p>Memory-augmented感兴趣</p><p><strong><em>Neural Response Generation with Meta-words</em></strong> Can Xu, wei wu, Chongyang Tao, Huang Hu, Matt Schuerman and Ying Wang</p><p>Meta-words很感兴趣</p><p><strong><em>OpenDialKG: Explainable Conversational Reasoning with Attention-based Walks over Knowledge Graphs</em></strong> Seungwhan Moon, Pararth Shah, Anuj Kumar and Rajen Subba</p><p>和Knowledge graph的结合</p><p><strong><em>E3: Entailment-driven Extracting and Editing for Conversational Machine Reading</em></strong> Victor Zhong and Luke Zettlemoyer</p><p><strong><em>Interconnected Question Generation with Coreference Alignment and Conversation Flow Modeling</em></strong> Yifan Gao, Piji Li, Irwin King and Michael R. Lyu</p><p><strong><em>Proactive Human-Machine Conversation with Explicit Conversation Goal</em></strong> Wenquan Wu, Zhen Guo, Xiangyang Zhou, Hua Wu, Xiyuan Zhang, Rongzhong Lian and Haifeng Wang</p><p><strong><em>Fine-Grained Sentence Functions for Short-Text Conversation</em></strong> Wei Bi, Jun Gao, Xiaojiang Liu and Shuming Shi</p><p><strong><em>Target-Guided Open-Domain Conversation</em></strong> Jianheng Tang, Tiancheng Zhao, Chenyan Xiong, Xiaodan Liang, Eric Xing and Zhiting Hu</p><p><strong><em>Microsoft Icecaps: An Open-Source Toolkit for Conversation Modeling</em></strong> Vighnesh Leonardo Shiv, Chris Quirk, Anshuman Suri, Xiang Gao, Khuram Shahid, Nithya Govindarajan, Yizhe Zhang, Jianfeng Gao, Michel Galley, Chris Brockett, Tulasi Menon and Bill Dolan</p><p>小冰升级了么…</p><p><strong><em>Sentence Level Curriculum Learning for Improved Neural Conversational Models</em></strong> Sean Paulsen</p><p>Curriculum Learning很感兴趣</p><h2 id="general-nlp">General NLP</h2><p><strong><em>Towards Explainable NLP: A Generative Explanation Framework for Text Classification</em></strong> Hui Liu, Qingyu Yin and William Yang Wang</p><p>这个看标题挺厉害的…</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;不久前放出了ACL2019的paper list, 但是还没有具体的文章，这里立一些flag, 找一些感兴趣的paper来读。&lt;/p&gt;
&lt;h2 id=&quot;text-style-transfer&quot;&gt;Text style transfer&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;
      
    
    </summary>
    
      <category term="Paper notes" scheme="http://yoursite.com/categories/Paper-notes/"/>
    
    
      <category term="emotion" scheme="http://yoursite.com/tags/emotion/"/>
    
      <category term="dialog system" scheme="http://yoursite.com/tags/dialog-system/"/>
    
      <category term="conversation generation" scheme="http://yoursite.com/tags/conversation-generation/"/>
    
      <category term="text style transfer" scheme="http://yoursite.com/tags/text-style-transfer/"/>
    
      <category term="personalization" scheme="http://yoursite.com/tags/personalization/"/>
    
  </entry>
  
  <entry>
    <title>小冰如何生成个性化回复</title>
    <link href="http://yoursite.com/2019/07/08/xiaobing/"/>
    <id>http://yoursite.com/2019/07/08/xiaobing/</id>
    <published>2019-07-08T00:46:22.000Z</published>
    <updated>2019-07-08T14:09:28.902Z</updated>
    
    <content type="html"><![CDATA[<p>小冰被设计为一个18岁的女孩，可靠，富有同情，感性而幽默。</p><blockquote><p>The XiaoIce persona is designed as a 18-year-old girl who is always reliable, sympathetic, affectionate, and has a wonderful sense of humor.</p></blockquote><p>那这些属性在生成回复的时候如何产生影响呢？ 这里就涉及到两个模块：Empathetic Computing 和 Core Chat</p><h2 id="empathetic-computing">Empathetic Computing</h2><p>这部分包括：</p><ul><li>Contextual Query Understanding</li><li>User Understanding</li><li>Interpersonal Response Generation</li></ul><h3 id="contextual-query-understanding">Contextual Query Understanding</h3><p>这一部分就可以理解为是根据上下文进行query expansion, 做一些指代消歧，上下文补充等。 总的来说就是对输入query <span class="math inline">\(Q\)</span>, 结合上下文 <span class="math inline">\(C\)</span> (历史会话信息），生成带有上下文信息的query <span class="math inline">\(Q_c\)</span>:</p><p><span class="math display">\[Q_c = f_{cqu}(Q, C)\]</span></p><h3 id="user-understanding">User Understanding</h3><p>这一部分是根据上下文 <span class="math inline">\(C\)</span> 和 query <span class="math inline">\(Q_c\)</span> 生成用户的信息 <span class="math inline">\(e_Q\)</span>，是一个用户共情向量，包括用户的属性信息（如果有的话），对话的topic, intent；也还包括emotion 和 sentiment的分析；<span class="math inline">\(e_Q\)</span>就如下图（一直用neural来表示中立，不知道是不是typo…)：</p><figure><img src="https://upload-images.jianshu.io/upload_images/2675254-09a2c70e80ce9bca.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><figcaption>image.png</figcaption></figure><p>形式化就是：</p><p><span class="math display">\[e_Q = f_{uu}(Q_c, C)\]</span></p><h3 id="interpersonal-response-generation">Interpersonal Response Generation</h3><p>这一部分是通过<span class="math inline">\(e_Q\)</span>中的会话信息和小冰预设的 persona profile (key-value pairs) 生成一个回复共情向量<span class="math inline">\(e_R\)</span>:</p><figure><img src="https://upload-images.jianshu.io/upload_images/2675254-129d192aff85f8f5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image1.png"><figcaption>image1.png</figcaption></figure><p>形式化就是：</p><p><span class="math display">\[e_R = f_{irg}(e_R, Persona\  profile\  of \ Xiaoice)\]</span></p><h2 id="core-chat">Core Chat</h2><p>有了上述的 <span class="math inline">\(\{Q_c, C, e_Q, e_R\}\)</span> 之后，在这部分结合这些信息生成回复。我这里只比较关系如何用generation-based方法去生成，如下图所示：</p><figure><img src="https://upload-images.jianshu.io/upload_images/2675254-ce68704903dae579.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><figcaption>image.png</figcaption></figure><p>模型基于RNN的seq2seq model, 将 <span class="math inline">\(Q_c\)</span> 作为 encoder的输入，得到hidden state vector再输入到decoder; 而在解码每个词的时候，都是通过一个包含了<span class="math inline">\(e_Q, e_R\)</span> 信息的向量 <span class="math inline">\(v\)</span> 去加入上下文和小冰的属性信息；而这个 <span class="math inline">\(v\)</span> 是通过如下公式来得到：</p><p><span class="math display">\[v = \sigma (W^T_Qe_Q + W^T_Re_R)\]</span></p><p>（我猜想每次结合的方式就是 <span class="math inline">\(v\)</span> 和 当前输入词向量<span class="math inline">\(e_t\)</span> concat一起之后再过一个线性层去规范维度</p><hr><p>通过以上这两个部分，小冰就能生成个性化的回复； 其实还是有两个点比较简单：</p><ol type="1"><li>对于属性的描述，用了很简单的key-value直接输入，对于具体属性如何影响回复生成并没有更深的modeling;</li><li>属性的表达上，其实也是比较简单的作用在了每次解码结合同样的信息，参考Emotional Chatting Machine这篇paper的思路的话，其实表达方式上，也是有一些多变的因素的。</li></ol><p>当然，可能具体使用上没办法去部署比较复杂的模型，也可能是因为小冰的数据足够多，而且其实大部分都还是用检索式，所以整体呈现的效果还确实不错~</p><h2 id="ref">Ref:</h2><p>Zhou L, Gao J, Li D, et al. The design and implementation of XiaoIce, an empathetic social chatbot[J]. arXiv preprint arXiv:1812.08989, 2018.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;小冰被设计为一个18岁的女孩，可靠，富有同情，感性而幽默。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The XiaoIce persona is designed as a 18-year-old girl who is always reliable, sympathet
      
    
    </summary>
    
      <category term="Paper notes" scheme="http://yoursite.com/categories/Paper-notes/"/>
    
    
      <category term="dialog system" scheme="http://yoursite.com/tags/dialog-system/"/>
    
      <category term="conversation generation" scheme="http://yoursite.com/tags/conversation-generation/"/>
    
      <category term="personalization" scheme="http://yoursite.com/tags/personalization/"/>
    
  </entry>
  
  <entry>
    <title>Generating Multiple Diverse Responses for Short-Text Conversation</title>
    <link href="http://yoursite.com/2019/07/04/Mul_response/"/>
    <id>http://yoursite.com/2019/07/04/Mul_response/</id>
    <published>2019-07-04T00:46:22.000Z</published>
    <updated>2019-07-08T14:09:28.898Z</updated>
    
    <content type="html"><![CDATA[<p>Paper链接: https://arxiv.org/abs/1811.05696</p><p>腾讯AI Lib的一篇paper, 发在 AAAI2019, 主要是解决对话中“一对多”的问题</p><p>目前我们做对话生成的模型大多都是基于seq2seq, 因为在 machine translation or text summarization 的任务中，文本生成的效果确实不错。 但是本质上，seq2seq是一个“一对一”的问题，然而对话，可能存在一个post，多种回复（语义不相同，没有词overlap)都是合适的。退一步讲，我们经常用的对话数据如微博, twitter，这些数据本身也是一对多（多条评论）的。</p><h3 id="problem-formulation">Problem formulation</h3><p>训练数据为 <span class="math inline">\(\{ (x, \{ y \} )\}\)</span>, 即给定一个query <span class="math inline">\(x\)</span>, 目标是去生成一个responses的集合 <span class="math inline">\(\{ y \}\)</span>, 通过引入一个中间变量 <span class="math inline">\(z\)</span> 建立 <span class="math inline">\(x\)</span> 和 $ { y } $ 的联系; 具提来说是去最小化loss:</p><p><span class="math display">\[ J(\theta) = \mathcal L( \{ y \}| x) = \mathbf E_{p(z|x) }[\mathcal L(\{y\}|x,z)]\]</span></p><p>而中间这个 <span class="math inline">\(z\)</span> , 作者是用一些采样出来的words来表示的。相应的，<span class="math inline">\(p(z|x)\)</span> 就是words 的 distribution. 作者用了一个一个双向 GRU 来 encode <span class="math inline">\(x\)</span> to <span class="math inline">\(h_x\)</span>, 再过一个softmax去算<span class="math inline">\(z\)</span> 的概率分布，就像一个简单的分类器：</p><p><span class="math display">\[p(z|x) = softmax(W_2 \cdot tanh(W_1h_x + b_1) + b_2)\]</span></p><p>这个中间变量 <span class="math inline">\(z\)</span> 应该遵循</p><ul><li>可解释性：能解释与 <span class="math inline">\(x\)</span> 和 $ { y } $ 的联系</li><li>有区分度， 不同的 <span class="math inline">\(x\)</span> 应该产生不同的 <span class="math inline">\(z\)</span></li></ul><blockquote><p>虽然用采样出来的 words 能够满足这两点，但还是不很理解为什么用 words 作为中间变量，离散的words相当于割裂了两部分，直接用分布不好吗？去掉中间的采样过程？</p></blockquote><p>而对于 <span class="math inline">\(\mathcal L(\{y\}|x,z)\)</span>, 由于是估计多个 <span class="math inline">\(\mathbf y\)</span>, 那么作者做了一个简单的架设，用一个可微的函数 <span class="math inline">\(f\)</span> 把预测单个 <span class="math inline">\(\mathbf y\)</span> 的估计联合在了一起： <span class="math display">\[\mathcal L(\{y\}|x,z) = f_{\mathbf y\in\{y\}}(\mathcal l(\mathbf y|x, z))\]</span></p><h3 id="model">Model</h3><p>模型架构如下：</p><figure><img src="https://upload-images.jianshu.io/upload_images/2675254-9f6ba40e800dfdab.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><figcaption>image.png</figcaption></figure><p>每次估计单个 <span class="math inline">\(\mathbf y\)</span> 的时候， 作者每一步将</p><ul><li>当前步骤的 hidden states <span class="math inline">\(h_y(t)\)</span></li><li><span class="math inline">\(x\)</span> 和 <span class="math inline">\(z\)</span> 的attention</li><li>解码过程 <span class="math inline">\(h_{\mathbf y}(t)\)</span> 和 <span class="math inline">\(x\)</span> 的 attention</li></ul><p>结合在一起去解码每一个词。</p><p>至于可微函数 <span class="math inline">\(f\)</span>, 考虑到多个 <span class="math inline">\(\mathbf y\)</span> 中，与 之前的 $ z $ 最相关的<span class="math inline">\(\mathcal L(\{y\}|x,z)\)</span> 应该最小，所以，这个 <span class="math inline">\(f\)</span> 就简单采用了 min函数：</p><p><span class="math display">\[f(\{y\}|x,z) = \min_{\mathbf y \in \{ y\}} \mathcal l(\mathbf y |x, z)\]</span></p><h3 id="training-with-rl">Training with RL</h3><p>前半部分 Modeling <span class="math inline">\(p(z|x)\)</span>, 是一个典型的生成词 (采样词) 的过程，作者这里用了RL里面的Policy Gradient去优化这个过程;</p><ul><li>为了缩小采样空间，作者先基于 $ x$ 和所有可能的<span class="math inline">\(\{y\}\)</span>构建了一个候选集 <span class="math inline">\(\mathbf Z_x\)</span>;</li><li>为了增加 <span class="math inline">\(K\)</span> 次采样 <span class="math inline">\(z\)</span> 的多样性, 作者增加了一些在 <span class="math inline">\(\mathbf Z_x\)</span> 聚类和判重的技巧；</li></ul><p>Reward function 被定义为了简单的 F1 score 来衡量每个生成的句子 <span class="math inline">\(\mathbf{\hat{y}}\)</span> 和 ground truth <span class="math inline">\(\mathbf y\)</span> 的 overlapping.</p><p>训练结束后，就可以用 <span class="math inline">\(p(z|x)\)</span> 概率 top-1000 的词作为候选集 <span class="math inline">\(\mathbf Z_x\)</span>, 然后再进行如上聚类和采样的过程，去生成多个responses.</p><h3 id="实验">实验</h3><p>实验数据就是用了微博和Twitter的数据，后面作者有公开源码和数据； Evaluation matrics用了 BLEU 和 Distinct-1/2, 其实感觉作者定义的 reward 函数就有点像 BLEU 这个metric…</p><blockquote><p>不太知道这样定义合不合适，因为BLEU，和作者定义的reward函数都是比较粗糙的去衡量生成文本的质量。这样就导致了这个问题有些强行拟合指标的嫌疑…</p></blockquote><h3 id="总结">总结</h3><p>这个问题很新，也比较切合实际，算是在挖一个很好的坑；</p><p>不过中间的一些过程可以尝试改进的地方应该还有很多，比如中间变量的设置，比如后面的reward函数</p><p>甚至，如果没有中间的离散变量，是不是也可以不用RL的方法去优化呢？</p><p>作者开放了源码：https://ai.tencent.com/ailab/nlp/dialogue.html</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Paper链接: https://arxiv.org/abs/1811.05696&lt;/p&gt;
&lt;p&gt;腾讯AI Lib的一篇paper, 发在 AAAI2019, 主要是解决对话中“一对多”的问题&lt;/p&gt;
&lt;p&gt;目前我们做对话生成的模型大多都是基于seq2seq, 因为在 ma
      
    
    </summary>
    
      <category term="Paper notes" scheme="http://yoursite.com/categories/Paper-notes/"/>
    
    
      <category term="dialog system" scheme="http://yoursite.com/tags/dialog-system/"/>
    
      <category term="conversation generation" scheme="http://yoursite.com/tags/conversation-generation/"/>
    
  </entry>
  
  <entry>
    <title>读博第一年（2018~2019）</title>
    <link href="http://yoursite.com/2019/06/17/2018_2019/"/>
    <id>http://yoursite.com/2019/06/17/2018_2019/</id>
    <published>2019-06-17T08:46:22.000Z</published>
    <updated>2019-06-17T07:25:32.818Z</updated>
    
    <content type="html"><![CDATA[<p>其实意识到，很多事情都会随着成长而改变。</p><p>所以就想记录一下自己对各个问题当下的看法，也算是记录一些经历。</p><h2 id="读博学术">读博（学术）</h2><p>今年是2019， 去年的BERT一出来，原来那种改模型拼performance的想法慢慢的就佛了；</p><p>曾经想过一段时间如何去定位自己的工作；</p><p>后来渐渐的理解是，想要水论文，做一些有意思的新应用场景;</p><p>大厂，业界短期内不会商用的，或是现有阶段不适合，不支持业界部署的问题</p><p>像是做demo，绕开正面刚技术；</p><p>这种问题重在innovation, 如果好的想法做的完备，就比较适合通用的AI的刊和会去投；</p><p>至于NLP领域内，这类work的 contribution可能不会被大多做技术的认可。</p><h2 id="爱情">爱情</h2><p>目前的想法，其实没有什么精力去分给爱情…</p><p>感觉每天分给爱情的时间其实也就半个小时跟女票聊聊天</p><p>女票不粘人，我们各自都有很好的发展和规划，也远不到一起认真规划以后结婚生活的阶段</p><p>所以现在就是享受爱情</p><h2 id="金钱">金钱</h2><p>现阶段每个月会存下一些钱，但是也不是很多</p><p>买买港股小米的股票，或者定投就好了..</p><p>平时对生活质量的要求不算太高，有什么硬需求尽量满足就可以了</p><p>这一部分，没什么钱，也就没什么规划了</p><h2 id="人际关系">人际关系</h2><p>感觉学术里social其实还是个圈子的问题…</p><p>其实主动可以，我其实加了很多能接触到的NLP内比较厉害的人</p><p>但是更多的就是朋友圈点个赞</p><p>自己没有什么成果的，或者比较好的想法的话，空去谈合作，成功率可能不高</p><p>没人有义务带自己</p><p>所以我的理解就是先证明自己有能力发论文，然后再主动去谈合作吧…</p><p>不知道算不算拖延..</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;其实意识到，很多事情都会随着成长而改变。&lt;/p&gt;
&lt;p&gt;所以就想记录一下自己对各个问题当下的看法，也算是记录一些经历。&lt;/p&gt;
&lt;h2 id=&quot;读博学术&quot;&gt;读博（学术）&lt;/h2&gt;
&lt;p&gt;今年是2019， 去年的BERT一出来，原来那种改模型拼performance的想法慢慢
      
    
    </summary>
    
      <category term="随感" scheme="http://yoursite.com/categories/%E9%9A%8F%E6%84%9F/"/>
    
    
  </entry>
  
  <entry>
    <title>Text style transfer papers</title>
    <link href="http://yoursite.com/2019/03/30/Text_style_transfer_papers/"/>
    <id>http://yoursite.com/2019/03/30/Text_style_transfer_papers/</id>
    <published>2019-03-30T09:17:30.000Z</published>
    <updated>2019-03-30T05:05:56.842Z</updated>
    
    <content type="html"><![CDATA[<h2 id="text-style-transfer">Text style transfer</h2><p>总结一下，Text style transfer可以分为两个部分：</p><ol type="1"><li>adverserial方法抽取semantic特征和style特征</li><li>如何生成特定style的句子</li></ol><p>模型，基本上都是VAE的天下。</p><p>存在的问题：</p><ol type="1"><li>目前没有人给text style一个很清晰的定义</li><li>很难把semantic 特征和style特征分得开(一些词既可以表达semantic信息，同时也可以表达style信息)</li><li>特定的style 和 特定的semantic 的合成句子质量很难有很好的表现</li><li>没有suitable的 evaluation方法</li></ol><p><strong>语言是基于符号的，符号的规则又是有限的（又是离散符号</strong></p><p><strong>或许从更上一层，考虑到人在生成想要表达的语言的思维（或许是连续的），如何去拟合可能限制会更少，并且更加流畅</strong></p><h3 id="what-is-wrong-with-style-transfer-for-texts"><font color="green">What is wrong with style transfer for texts?</font></h3><p>主要介绍了一些目前text style transfer的问题，比较适合去找research gap.</p><ul><li>Text style 的定义不太清晰，无法准确建模</li><li>Adverserial net 的方法很难剥离 content 和 style</li></ul><h3 id="style-transfer-from-non-parallel-text-by-cross-alignmentnips-2017">Style Transfer from Non-Parallel Text by Cross-Alignment（NIPS 2017)</h3><p>重点在于非平行数据的分析； <strong>最印象深刻的是约束两个styles对应的content同分布</strong>； 同时，做法也是adverserial的方式分离content 和 style 然后再生成</p><h3 id="evaluating-style-modification-in-text">Evaluating Style Modification in Text</h3><p>一个Master的毕业论文吧。。 首先提到了一个 <strong>word mover’s distance on texts with style masked out 我觉得这个应用到我们的model里去找同样content的句子是一个很好的方式 （这个应该是一个保留了sequencial和content信息的相似度衡量）</strong></p><p>主要从这几个方面入手：</p><figure><img src="http://static.zybuluo.com/Preke/9t4yzetlwbmu8q3x2nds8lnv/image_1d76fo7fc1n5a1hl6gjnju9k57m.png" alt="Evaluating Style Modification in Text"><figcaption>Evaluating Style Modification in Text</figcaption></figure><p><strong>提到一个mask style words的方法去做content preserving</strong>； 这里可能可以用到去：</p><ul><li>训练auto-encoder</li><li>寻找对应sentence</li></ul><p>有个Wordnet的Style-lexicon</p><p>这几种度量方法可以借鉴</p><h3 id="style-transfer-in-text-exploration-and-evaluation">Style Transfer in Text: Exploration and Evaluation</h3><p>用对抗的方法去剥离style信息 from content信息</p><p>propose two novel evaluation metrics：</p><ul><li>transfer strength</li><li>content preservation</li></ul><h3 id="evaluating-prose-style-transfer-with-the-bible">Evaluating prose style transfer with the Bible</h3><p>主要是提供了一个Bible的Text style transfer的平行数据集</p><h3 id="a-monolingual-tree-based-translation-model-for-sentence-simplification">A Monolingual Tree-based Translation Model for Sentence Simplification</h3><p>简化句子，类似于text summerization, 和 style transfer的区别和联系呢？</p><p>利用传统方法（语法解析树）的方式去做</p><h3 id="generating-sentences-from-a-continuous-space"><font color="green">Generating Sentences from a Continuous Space</font></h3><p>本文讲的这个问题也是我比较感兴趣的一个问题： &gt; However, by breaking the model structure down into a series of next-step predictions, the rnnlm does not expose an interpretable representation of global features like topic or of high-level syntactic properties.</p><p>用VAE能够学到一个全局的特征like style， topic and high-level syntactic features 去解决imputing missing words(补全缺失词) 的问题</p><p>我觉得肯定是可以用到style-transfer里去抽取特征的</p><h3 id="multiple-attribute-text-rewriting"><font color="green">MULTIPLE-ATTRIBUTE TEXT REWRITING</font></h3><p>用back-translation的方法去掉style，看一下是怎么论述不需要分开style-attribute这个说法的</p><h3 id="toward-controlled-generation-of-text">Toward Controlled Generation of Text</h3><p>用VAE的方法去生成特定的sentiment 或者 tenses的句子</p><h3 id="unpaired-sentiment-to-sentiment-translation-a-cycled-reinforcement-learning-approach">Unpaired Sentiment-to-Sentiment Translation: A Cycled Reinforcement Learning Approach</h3><p>用强化学习的方法去转换情感 还是一个先remove词语，再去生成的一个方法</p><h3 id="adversarially-regularized-autoencoders">Adversarially Regularized Autoencoders</h3><p>VAE, CVAE, AAE, ARAE, DAE</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;text-style-transfer&quot;&gt;Text style transfer&lt;/h2&gt;
&lt;p&gt;总结一下，Text style transfer可以分为两个部分：&lt;/p&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;adverserial方法抽取semantic特征和s
      
    
    </summary>
    
      <category term="Paper notes" scheme="http://yoursite.com/categories/Paper-notes/"/>
    
    
      <category term="Text style transfer" scheme="http://yoursite.com/tags/Text-style-transfer/"/>
    
  </entry>
  
  <entry>
    <title>Sentiment analysis papers</title>
    <link href="http://yoursite.com/2019/03/27/Sentiment_analysis_papers/"/>
    <id>http://yoursite.com/2019/03/27/Sentiment_analysis_papers/</id>
    <published>2019-03-27T09:17:30.000Z</published>
    <updated>2019-03-27T16:01:30.972Z</updated>
    
    <content type="html"><![CDATA[<h2 id="sentiment-analysis12-papers">Sentiment analysis（12 papers)</h2><p>直观感受是，但从sentiment这个角度讲</p><ul><li>单纯bag-of-words 目前已经不够了</li><li>Lexicons很重要</li><li>Word roles(POS)很重要</li><li>句法信息也很重要，但是不太好直接用</li><li>模型方面基本上baseline就是(Bi)LSTM+Attn了</li></ul><h3 id="sentiment-lexicon-enhanced-attention-based-lstm-for-sentiment-classification">Sentiment Lexicon Enhanced Attention-Based LSTM for Sentiment Classification</h3><p><font color="red">Current NN works 很少用到 Lexicons</font></p><p>Title 很好描述了本文工作</p><h3 id="a-multi-sentiment-resource-enhanced-attention-network-for-sentiment-classification">A Multi-sentiment-resource Enhanced Attention Network for Sentiment Classification</h3><p>Deep learning approaches for sentiment classification do not fully exploit <font color="red">sentiment linguistic knowledge.</font></p><ul><li>sentiment lexicon(此处有词干化，精细化处理）</li><li>negation words</li><li>intensity words</li></ul><p>sentiment resource 做 attention</p><h3 id="encoding-syntactic-knowledge-in-neural-networks-for-sentiment-classification">Encoding Syntactic Knowledge in Neural Networks for Sentiment Classification</h3><p>Rich <font color="red">syntactic knowledge</font> has not been fully explored when composing a longer text from its shorter constituent words</p><p>We discover that <strong>encoding syntactic knowledge (part-of-speech tag) in neural networks can enhance sentence/phrase representation</strong></p><p><code>tree-structured LSTM</code></p><p>其实出发点就是把句法信息加到模型中，这么说，其实语言也不单纯是一个sequencial的信息，但是为什么Tree-LSTM没有更加流行起来可能就是因为语法解析树太难了….不是目前大量跳AI坑的人说做就做的…</p><p>这个想法很有意思:</p><p><font color="red"><strong>We define sentiment-favorable representation as what is learned by a proper way of expressing sentiment, and is usually optimized with a sentiment-specific loss.</strong></font></p><h3 id="a-lexicon-based-supervised-attention-model-for-neural-sentiment-analysis">A Lexicon-Based Supervised Attention Model for Neural Sentiment Analysis</h3><p>Allows a recurrent neural network to <strong>focus on the sentiment content</strong>, thus generating <strong>sentiment-informative representations</strong>.</p><p>Sentiment degree based on sentiment lexicons (Attention 的权重）</p><h3 id="leveraging-multi-grained-sentiment-lexicon-information-for-neural-sequence-models">Leveraging Multi-grained Sentiment Lexicon Information for Neural Sequence Models</h3><p><strong>Multi-grained Sentiment Lexicon</strong> 多粒度级别Lexicons</p><p>The proposed method first <font color="red">encodes the fine-grained labels into sentiment embedding</font> and <font color="red">concatenates it with word embedding</font>.</p><figure><img src="http://static.zybuluo.com/Preke/9wma6ml3vpoglune4o3udj3n/image_1d6v2lakt12a69gtt1p1lr77l99.png" alt="image_1d6v2lakt12a69gtt1p1lr77l99.png-117.2kB"><figcaption>image_1d6v2lakt12a69gtt1p1lr77l99.png-117.2kB</figcaption></figure><p>这里说到表示程度的，否定词，都对分类有帮助。</p><p>提供了一个 Sentiment lexicon which contains:</p><ul><li>2759 positive words,</li><li>5111 negative words,</li><li>35 negation words and</li><li>62 intensifiers</li></ul><p>https://github.com/zengyan-97/Sentiment-Lexicon</p><h3 id="context-sensitive-lexicon-features-for-neural-sentiment-analysis"><font color="green">Context-Sensitive Lexicon Features for Neural Sentiment Analysis</font></h3><p>Most existing methods use sentiment lexicons without considering context, typically taking the count, sum of strength, or maximum sentiment scores over the whole input.(应该是一个比较重要的research gap)</p><p>Previous works:</p><ul><li>they do not explicitly handle semantic compositionality</li><li>they cannot effectively deal with word sense variations</li></ul><p>Model looks like:</p><figure><img src="http://static.zybuluo.com/Preke/u0zdwflmj1hpcqa2qxqocct3/image_1d6v3ll4hhk81mhkl1c1dat1ecb9.png" alt="image_1d6v3ll4hhk81mhkl1c1dat1ecb9.png-73.7kB"><figcaption>image_1d6v3ll4hhk81mhkl1c1dat1ecb9.png-73.7kB</figcaption></figure><h3 id="linguistically-regularized-lstm-for-sentiment-classification"><font color="green">Linguistically Regularized LSTM for Sentiment Classification</font></h3><p>在一个句子中不同的词，功能不同，对表征的贡献不同，本文是去find the role of the different kind of words.</p><p>Models are able to capture the <strong>linguistic role of sentiment words, negation words, and intensity words</strong> in sentiment expression.</p><p>our central idea is <font color="red">to regularize the difference between the predicted sentiment distribution of the current position, and that of the previous or next positions, in a sequence model</font>.</p><p>理解sentiment distribution? 和 style distribution 有何联系</p><h3 id="incorporating-lexicons-into-lstm-for-sentiment-classification">Incorporating Lexicons into LSTM for Sentiment Classification</h3><p>印鉴老师的paper.</p><p>也是考虑了词语在不同语境下的语义不同这个问题；</p><p>根本上也是在根据 word 的 role 去增加knowledge</p><p>Words in different part-of-speech correspond to different meanings, emotional polarity and score. The same word may have multiple meanings.</p><h3 id="imbalanced-text-sentiment-classification-using-universal-and-domain-specific-knowledge">Imbalanced text sentiment classification using universal and domain-specific knowledge</h3><p>考虑情感分析的两个问题：</p><ul><li>domain-sensitive</li><li>data imbalance</li></ul><p>Builds a <strong>domain-adaptive sentiment classification model</strong> that incorporates universal and domain-specific knowledge into a unified learning framework.</p><h3 id="saan-a-sentiment-aware-attention-network-for-sentiment-analysis">SAAN: A Sentiment-Aware Attention Network for Sentiment Analysis</h3><p>3步工作：</p><ul><li>a word-level mutual attention mechanism to model word-level correlation</li><li>a phrase-level convolutional attention is designed to obtain phrase-level correlation</li><li>a sentence-level multi-head attention mechanism is proposed to capture various sentimental information from different subspaces.</li></ul><h3 id="laan-a-linguistic-aware-attention-network-for-sentiment-analysis">LAAN: A Linguistic-Aware Attention Network for Sentiment Analysis</h3><p>同上文一样…</p><h3 id="attention-based-bilstm-network-with-lexical-feature-for-emotion-classification">Attention-Based BiLSTM Network with Lexical Feature for Emotion Classification</h3><p>Propose two simple models to fully learn the emotional features of the POS of words.</p><ol type="1"><li>把每个词的POS-tag 和 LSTM 输出 拼在一起做 attention</li><li>分别用LSTM+attn 对 context 表示 和 POS标签（应该是做输入）学习，然后把最终特征拼一起</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;sentiment-analysis12-papers&quot;&gt;Sentiment analysis（12 papers)&lt;/h2&gt;
&lt;p&gt;直观感受是，但从sentiment这个角度讲&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;单纯bag-of-words 目前已经不够了&lt;/li&gt;
&lt;
      
    
    </summary>
    
      <category term="Paper notes" scheme="http://yoursite.com/categories/Paper-notes/"/>
    
    
      <category term="Sentiment analysis" scheme="http://yoursite.com/tags/Sentiment-analysis/"/>
    
  </entry>
  
  <entry>
    <title>Dialog system记录</title>
    <link href="http://yoursite.com/2019/01/01/dialog_system/"/>
    <id>http://yoursite.com/2019/01/01/dialog_system/</id>
    <published>2019-01-01T09:17:30.000Z</published>
    <updated>2019-01-03T02:56:19.561Z</updated>
    
    <content type="html"><![CDATA[<h2 id="section">2019.1.1</h2><p>找了一个代码实现了一下seq2seq(GRU+attention)在一个小的task based的数据集（44M）上的结果 发现BLEU最高也只能到6，而用英法翻译数据（1.5g）一个epoch之后，BLEU就达到了13+（时间太长没有继续跑下去</p><p>生成的很多有包含thanks for your feedback类似的，就是有可能生成一些general的response，并不能直接应用到生产环境中。</p><p>分析来看(推测）：</p><ol type="1"><li>数据量很小，不足以去训练seq2seq的model</li><li>task based可能还是更适合retrieval 的方法，generation的方法可能更适合free-talk</li></ol><p>code source: https://github.com/preke/FSE2019</p><h2 id="section-1">1.3</h2><p>昨晚和师兄讨论了一个domain adaption style transfer的idea; 师兄给了我一些已经写好的domain adaption的代码，然后结合这边原来写的seq2seq再完善一下，应该可以跑出来看看效果； 不过目前是要找到可以用的style transfer的数据集。</p><p>code source: https://github.com/preke/domain_adaption_style_transfer</p><h3 id="ref">ref:</h3><p>https://arxiv.org/abs/1804.06437 https://arxiv.org/pdf/1409.7495.pdf （目前参考这两个，但是应该会能够找到更多的一些paper在做这件事吧…）</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;section&quot;&gt;2019.1.1&lt;/h2&gt;
&lt;p&gt;找了一个代码实现了一下seq2seq(GRU+attention)在一个小的task based的数据集（44M）上的结果 发现BLEU最高也只能到6，而用英法翻译数据（1.5g）一个epoch之后，BLEU就达
      
    
    </summary>
    
      <category term="工作记录" scheme="http://yoursite.com/categories/%E5%B7%A5%E4%BD%9C%E8%AE%B0%E5%BD%95/"/>
    
    
      <category term="dialog system" scheme="http://yoursite.com/tags/dialog-system/"/>
    
  </entry>
  
  <entry>
    <title>Eliciting Positive Emotion through Affect-Sensitive Dialogue Response Generation A Neural Network Approach</title>
    <link href="http://yoursite.com/2018/11/14/EmoHERD/"/>
    <id>http://yoursite.com/2018/11/14/EmoHERD/</id>
    <published>2018-11-14T09:17:30.000Z</published>
    <updated>2018-11-20T11:34:09.638Z</updated>
    
    <content type="html"><![CDATA[<h2 id="abstract">Abstract</h2><ul><li><p>We build a fully data driven chat-oriented dialogue system that can dynamically mimic affective human interactions by utilizing a neural network architecture.</p></li><li><p>we propose a sequence-to-sequence response generator that <strong>considers the emotional context</strong> of the dialogue.</p></li><li><p>shows that incorporation of emotion into the training process helps reduce the perplexity of the generated responses,</p></li></ul><h2 id="model">Model</h2><ul><li>经典HERD</li></ul><figure><img src="http://static.zybuluo.com/Preke/r5an3or08it4vnq8btaamoy7/image_1cs8ufb1t1i1o17ep19m0162r11nqm.png" alt="HERD"><figcaption>HERD</figcaption></figure><p>(这个可以做多轮对话呀） <br></p><ul><li>Emo-HERD<ul><li>Incorporate an <strong>emotion encoder</strong> into the HRED architecture</li><li>The emotion encoder is placed in the same hierarchy as the dialogue encoder, capturing emotion at dialogue-turn level and maintaining the emotion context history throughout the dialogue</li></ul></li></ul><figure><img src="http://static.zybuluo.com/Preke/nvbhd3dqvy32dot5ihytdz20/image_1cs8sg97q1ij3ts92kc1s8a15sv2t.png" alt="Emo-HERD"><figcaption>Emo-HERD</figcaption></figure><p>在对单轮对话生成 <span class="math inline">\(h_{dlg}\)</span> 之后，把 <span class="math inline">\(h_{dlg}\)</span> 输入到一个 emotion encoder中结合历史信息 <span class="math inline">\(h_{m-1}^{emo}\)</span> 生成emotion embedding <span class="math inline">\(h_{emo}\)</span></p><figure><img src="http://static.zybuluo.com/Preke/rr7tkqgcm4oid3taya7446e8/image_1cs8uknnk9h014du17h0825bcl13.png" alt="generate hemo"><figcaption>generate hemo</figcaption></figure><p>emotion encoder这里有自己的损失函数 <span class="math inline">\(cost_{emo}\)</span> 总的Emo-HERD的损失函数为: <img src="http://static.zybuluo.com/Preke/cazlc4pzfpab4iq08x1qn6dz/image_1cs8uvs1ni5qr501061v9t1q0f1g.png" alt="cost"></p><h2 id="metrics">Metrics:</h2><ul><li>perplexity</li><li>subjective evaluation to measure the <strong>naturalnes</strong>s and <strong>emotional impact</strong> of the generated responses</li></ul><h2 id="dataset">Dataset</h2><ul><li>SubTle, a large scale conversational corpus</li><li>Spontaneous affective conversational corpus</li><li>Constructing positive-emotion eliciting data</li></ul><h2 id="section"></h2><h2 id="acquisition">Acquisition：</h2><ul><li>utterance: Dialog中一轮对话中的一个<font color="red">(单方的?）</font> sentences (感觉从原文看是这样的）</li></ul><p>感觉有点蹭热点的嫌疑呀，14年的HERD, 加上了一个emotion encoder就发了… 反正帮助我理解HERD了吧…</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;We build a fully data driven chat-oriented dialogue system that can dynamically mimic affective 
      
    
    </summary>
    
      <category term="Paper notes" scheme="http://yoursite.com/categories/Paper-notes/"/>
    
    
      <category term="emotion" scheme="http://yoursite.com/tags/emotion/"/>
    
      <category term="dialog system" scheme="http://yoursite.com/tags/dialog-system/"/>
    
      <category term="conversation generation" scheme="http://yoursite.com/tags/conversation-generation/"/>
    
  </entry>
  
  <entry>
    <title>A Syntactically Constrained Bidirectional-Asynchronous Approach for Emotional Conversation Generation</title>
    <link href="http://yoursite.com/2018/11/14/slstm/"/>
    <id>http://yoursite.com/2018/11/14/slstm/</id>
    <published>2018-11-14T09:17:30.000Z</published>
    <updated>2018-11-13T18:07:59.767Z</updated>
    
    <content type="html"><![CDATA[<h2 id="abstract">Abstract</h2><ul><li><p>poor logic and no emotion</p></li><li><p>a syntactically con- strained bidirectional-asynchronous approach for <code>emotional conversation generation</code> (E- SCBA) is proposed</p></li><li><p>In our model, pre-generated emotion keywords and topic keywords are asynchronously introduced into the process of decoding.</p></li></ul><h2 id="contribution">Contribution</h2><ol type="1"><li>It conducts a study of compound information, which constitutes the syntactic constraint in the conversation generation.</li><li>A bidirectional-asynchronous decoder with multi-stage strategy is proposed to utilize the syntactic constraint.</li><li>Our experiments show that E-SCBA work better on emotion, logic and diversity than the general seq2seq and other models that consider only a sin- gle factor during the generation.</li></ol><h2 id="dataset">Dataset</h2><ul><li>Emotional conversation dataset NLPCC2017</li><li>1,119,201 Chinese post-reply pairs</li><li>randomly sampled 8,000 for validation, 3,000 for testing and the rest for training</li></ul><h2 id="model">Model</h2><figure><img src="http://static.zybuluo.com/Preke/57nvin5t51ekhs4b8mtfki27/image_1cs61nfsh165dh4c1ph8bjpjagp.png" alt="image_1cs61nfsh165dh4c1ph8bjpjagp.png-328.8kB"><figcaption>image_1cs61nfsh165dh4c1ph8bjpjagp.png-328.8kB</figcaption></figure><p>Keywords dictionary: 1. Emotion dictionary 2. Topic dictionary</p><ul><li>Step1: 输入Post, 得到topic keyword and emotion keyword<ul><li>pretrained LDA 主题推断</li><li>emotion transfer network 得到emotion</li><li>(一些网络处理）得到topic keyword and emotion keyword that are expected to appear in the reply.</li></ul></li><li>Step2:<ul><li>Post过LSTM(加入Emotion keyword), 得到一系列hidden vectors <span class="math inline">\(\{s_i^{et}\}\)</span><br></li><li>Post过LSTM(加入Topic keyword, Emotional attention), 得到一系列hidden vectors <span class="math inline">\(\{s_j^{tp}\}\)</span></li><li><font color="red">LSTM和Attention的常用结合方式？</font></li><li>用<span class="math inline">\(\{s_i^{et}\}\)</span> 去 attention <span class="math inline">\(\{s_j^{tp}\}\)</span> 得到 <strong>Middle Sequence(<span class="math inline">\(y^{md}\)</span>)</strong> (这里<span class="math inline">\(y^{md}\)</span> 不代表输出的words, 仅仅是中间变量而已）如图：get middle sequence</li><li>然后通过<span class="math inline">\(y^{md}\)</span> 得到 <span class="math inline">\(y^{ce}\)</span> 和 <span class="math inline">\(y^{ct}\)</span> 如图：get ce and ct <img src="http://static.zybuluo.com/Preke/4edy641z8lopisgm15bogwu5/image_1cs728vnp1bsp1743gko17mcn379.png" alt="get middle sequence"> <br></li></ul></li></ul><figure><img src="http://static.zybuluo.com/Preke/qt9plkibwr5fvzt7wzwncnvi/image_1cs72kfu14s0s3b15am52fv88m.png" alt="get ce and ct"><figcaption>get ce and ct</figcaption></figure><blockquote><p>提醒自己一点，LSTM每个输出也只是hidden states, 具体应用到decoder是还要加入一个选择当前输出词语的softmax:<span class="math inline">\(P(w_i|w_{i-1}, h_i, c_i)\)</span></p></blockquote><ul><li>Step3:<br>concat 所有的东西 together: <span class="math inline">\(y^f=(y^{ct,b}, w_{tp}^k, y^{md,f}, w_{et}^k, y^{ce,f})\)</span> <span class="math inline">\(y^b\)</span> 就是 <span class="math inline">\(y^f\)</span> 的反向; And then 得到最终的hidden states 然后生成words:</li></ul><figure><img src="http://static.zybuluo.com/Preke/zptciuvc45fjyf2ffwj4ep1d/image_1cs739mit1j9lb0916ii3e7vvm9.png" alt="get hidden states"><figcaption>get hidden states</figcaption></figure><h2 id="experiment-and-metrics">Experiment and Metrics</h2><ul><li><strong>Embedding-based Metrics</strong>: We measure the similarity computed by <strong>cosine distance</strong> between a candidate reply and the target reply using <strong>sentence-level embedding</strong></li><li><strong>Distinct Metrics</strong>: By computing the number of different unigrams (Distinct-1) and bigrams (Distinct-2), we measure information and diversity in the candidate replies</li><li><strong>Human Annotations</strong></li></ul><h2 id="acquisition">Acquisition：</h2><p>方向的变换看不太懂，lstm的一些认识加深了一点</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;poor logic and no emotion&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;a syntactically con- strained bidirectional-asynchrono
      
    
    </summary>
    
      <category term="Paper notes" scheme="http://yoursite.com/categories/Paper-notes/"/>
    
    
      <category term="dialog system" scheme="http://yoursite.com/tags/dialog-system/"/>
    
      <category term="conversation generation" scheme="http://yoursite.com/tags/conversation-generation/"/>
    
      <category term="sentiment" scheme="http://yoursite.com/tags/sentiment/"/>
    
  </entry>
  
  <entry>
    <title>Emotional Chatting Machine Emotional Conversation Generation with Internal and External Memory</title>
    <link href="http://yoursite.com/2018/11/14/ECM/"/>
    <id>http://yoursite.com/2018/11/14/ECM/</id>
    <published>2018-11-14T09:17:30.000Z</published>
    <updated>2018-11-20T11:30:03.551Z</updated>
    
    <content type="html"><![CDATA[<h2 id="abstract">Abstract</h2><p>In this paper, we propose Emotional Chatting Machine (ECM) that can generate appropriate responses not only in content (relevant and grammatical) but also in emotion (emotionally consistent).</p><p>ECM addresses the factor using three new mechanisms that respectively： - Models the high-level abstraction of emotion expressions by embedding emotion categories - Captures the change of implicit internal emotion states - Uses explicit emotion expressions with an <strong>external emotion vocabulary</strong></p><h2 id="contribution">Contribution</h2><ul><li>It proposes to address the <strong>emotion factor</strong> in large-scale conversation generation</li><li>It proposes an end-to-end framework (called ECM) to incorporate the emotion influence in large-scale conversation generation. It has three novel mechanisms: emotion category embedding, an internal emotion memory, and an external memory.</li><li>It shows that ECM can generate responses with higher content and emotion scores than the traditional seq2seq model.</li></ul><h2 id="problem">Problem:</h2><p>Given post $ X = [x_1,…x_n] $ and emotion factor <span class="math inline">\(e\)</span>, Output response <span class="math inline">\(Y = [y_1,...y_m]\)</span> coherent with the emotion <span class="math inline">\(e\)</span></p><p><span class="math display">\[P(Y|X,e)= \prod_{i=1}^m(P(y_i|y_{&lt;i},X,e)\]</span></p><h2 id="model">Model</h2><p><img src="http://static.zybuluo.com/Preke/3w8q9xm5wvlwbhfw133fpz7z/image_1csodth9h1ka6q9mcm7m3k1huf9.png" alt="ECM model"> 整体流程是： 先训练一个Emotion Classidier 来 annotate 训练数据的emotion; 然后将三元组(Post, response, target emotion)输入到ECM中，在decoder中结合target emotion的信息，依次生成每个word, (生成response) 然后再对response用同样的Emotion Classidier 做分类，得到response的情感来衡量效果</p><figure><img src="http://static.zybuluo.com/Preke/m8ewuvddl5icqvaw4wey1tqu/image_1csoduq9ah88e04f5m1qcso18m.png" alt="Internal Memory"><figcaption>Internal Memory</figcaption></figure><figure><img src="http://static.zybuluo.com/Preke/ded8bdig3g83wz5xe2w5a3di/image_1csodvkvn1af2b9n1r6c1mk51ilo13.png" alt="External Memory"><figcaption>External Memory</figcaption></figure><p>(中间的数学推断，看倒是看明白了，有点懒得誊一次…</p><h2 id="dataset">Dataset</h2><ul><li>NLPCC emotion classification dataset</li><li>STC conversation dataset *could found in the github: <a href="https://github.com/tuxchow/ecm" target="_blank" rel="noopener">source code</a></li></ul><h2 id="experiment-and-metrics">Experiment and Metrics</h2><ul><li>BLEU is not suitable for measuring conversation generation due to its low correlation with human judgment.</li><li>Perplexity(在读过的paper中最常见的）</li><li>Emotion accuracy</li></ul><figure><img src="http://static.zybuluo.com/Preke/0okuk2t5cip926nwjr4kokoa/image_1csoe3n91314cc21l9i16s8fom1g.png" alt="result1"><figcaption>result1</figcaption></figure><ul><li>Manual Evaluation</li></ul><h2 id="acquisition">Acquisition：</h2><p>过程感觉有点琐碎，细节上的修改和优化还是挺多的，不能说是一个很眼前一亮的工作吧（不是效果和问题不好，而是没那么直观），但是运行一下代码应该会有更加深的体会</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;In this paper, we propose Emotional Chatting Machine (ECM) that can generate appropriate responses not on
      
    
    </summary>
    
      <category term="Paper notes" scheme="http://yoursite.com/categories/Paper-notes/"/>
    
    
      <category term="emotion" scheme="http://yoursite.com/tags/emotion/"/>
    
      <category term="dialog system" scheme="http://yoursite.com/tags/dialog-system/"/>
    
      <category term="conversation generation" scheme="http://yoursite.com/tags/conversation-generation/"/>
    
  </entry>
  
  <entry>
    <title>Style Transfer in Text Exploration and Evaluation</title>
    <link href="http://yoursite.com/2018/11/14/style_transfer/"/>
    <id>http://yoursite.com/2018/11/14/style_transfer/</id>
    <published>2018-11-14T09:17:30.000Z</published>
    <updated>2018-11-20T11:33:55.933Z</updated>
    
    <content type="html"><![CDATA[<h2 id="abstract">Abstract</h2><p>2 main problems in Style Transfer:</p><ul><li>Lack of parallel data<ul><li>Model learn from <font color="red">non-parallel data</font></li><li>Learn separate <strong>content representations</strong> and <strong>style representations</strong> using <strong>adversarial networks</strong>.</li></ul></li><li>Lack of reliable metrics<ul><li>propose two novel evaluation metrics that measure two aspects of style transfer: <strong>transfer strength</strong> and <strong>content preservation</strong></li></ul></li></ul><h2 id="contribution">Contribution</h2><ul><li>Compose a <a href="https://github.com/fuzhenxin/textstyletransferdata" target="_blank" rel="noopener">dataset</a> of paper-news titles to facilitate the research in language style transfer</li><li>Propose <strong>two general evaluation metrics</strong> for style transfer, which considers both transfer strength and content preservation. The evaluation metric is highly correlated to the human evaluation.</li></ul><h2 id="model">Model</h2><p>(both only contains the content information)</p><h3 id="multi-encoder">multi-encoder</h3><ul><li>The multi-decoder model uses different decoders, one for each style, to generate texts in the corresponding style.</li></ul><p>困难在于encoder如何生成只含有content信息的representation，不包含原来的style信息<font color="red">（有点不理解是为什么…)</font></p><p>设置目标函数用adversarial network 处理post的style分类：目标是 to separate the content representation from the style. 这里有两个loss: <img src="http://static.zybuluo.com/Preke/qhmh4o4giu7h1z3krd3n9qnb/image_1cs8n1gskhhu11r3ket1g1kaqbs.png" alt="Loss1"> to minimizes the negative log probability of the style labels in the training data. (这里<span class="math inline">\(\theta_c\)</span> 是 predict style的分类器的参数） <img src="http://static.zybuluo.com/Preke/y8oee035db5o9qpekcx5mhok/image_1cs8n5qv9v9k11611sqv1tu415sq19.png" alt="Loss2"> by maximize the entropy (minimize the negative entropy) of the predicted style labels, make the classifier unable to identify the style of <span class="math inline">\(x\)</span></p><p>然后，对于多个不同style的decoder: 还有一个传统的loss, 使得输入输出的语义更相似<font color="red">（这里我也有点不太认同）</font> <img src="http://static.zybuluo.com/Preke/9b6a2z85xixmuk43xn11b85b/image_1cs8nfl7k14a91ro31stf5r11l5o1m.png" alt="loss gen"></p><p>所以这个multi-encoder的总体loss为： <img src="http://static.zybuluo.com/Preke/ee85f56nen42jcewrseks92w/image_1cs8ngdnh1m6h127l4nc1jol15823.png" alt="total loss"></p><h3 id="style-embedding">style embedding</h3><p>与上述模型类似，只是在参数中加入了所有style categoris的embeddings的矩阵<span class="math inline">\(E\in R^{N*d_s}\)</span> <span class="math inline">\(N\)</span> for the number of styles <span class="math inline">\(d_s\)</span> for the dim of style embeddings</p><p>这部分的Loss为： <img src="http://static.zybuluo.com/Preke/vo7860x0z6e0jd2643citxrq/image_1cs8nq9t11a4r71e1nh69k2l7q2g.png" alt="Loss2"></p><ul><li>The style-embedding model learns style embeddings addition to the content representations.</li></ul><figure><img src="http://static.zybuluo.com/Preke/e1obhx207tcemqi309feb66d/image_1cs8ea9g6ic51tk367h1ob07gs9.png" alt="2 models"><figcaption>2 models</figcaption></figure><h2 id="metrics">Metrics:</h2><ul><li>Transfer Strength<ul><li>evaluates whether the style is transferred to target style(用LSTM-sigmoid构建一个分类器，通过acc衡量）</li></ul></li><li>Content Preservation<ul><li>evaluate the similarity between source text and target text</li></ul></li></ul><h2 id="dataset">Dataset</h2><ul><li>paper-news title dataset</li><li>positive-negative review dataset</li></ul><h2 id="acquisition">Acquisition：</h2><p>Model很直观，只是对于adversarial 的思路还是不太理解，有一些不理解的点标红了 （感觉没有体现出Contribution中说的parallel数据的特点）</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;2 main problems in Style Transfer:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Lack of parallel data
&lt;ul&gt;
&lt;li&gt;Model learn from &lt;font col
      
    
    </summary>
    
      <category term="Paper notes" scheme="http://yoursite.com/categories/Paper-notes/"/>
    
    
      <category term="style transfer" scheme="http://yoursite.com/tags/style-transfer/"/>
    
  </entry>
  
  <entry>
    <title>Steering Output Style and Topic in Neural Response Generation</title>
    <link href="http://yoursite.com/2018/11/13/STO/"/>
    <id>http://yoursite.com/2018/11/13/STO/</id>
    <published>2018-11-13T09:17:30.000Z</published>
    <updated>2018-11-13T13:32:23.314Z</updated>
    
    <content type="html"><![CDATA[<h2 id="abstract">Abstract</h2><ul><li>We propose simple and flexible training and decoding methods for <strong>influencing output style and topic</strong> in neural encoder-decoder based language generation</li></ul><h2 id="model">Model</h2><h3 id="encoder-decoder">encoder-decoder</h3><p>Chapter 3 &amp; 4 解释了一对如何利用Bayes更好的设定目标函数从而s2s的decoder效果更好（更好的选择words)的数学解释，有点晕晕的。 （总之是在实验时对encoder-decoder进行了微调改进吧）</p><h3 id="chapter-5-style">Chapter 5: Style</h3><p>如果我们有一个数据集（database of target sentences) 在 neural encoder-decoder framework 的框架下，如何去影响style</p><ul><li>5.1 Ranking</li><li>Target is fixed</li><li><p>As a retrieval problem</p></li><li>5.2 Multiply<ul><li>2 models<ul><li>encoder-decoder model trained on a open-domain dataset</li><li>language model trained on target dataset</li></ul></li><li>在RNN step-by-step 生成each word 的概率为： <span class="math inline">\(P(t|S)^{\lambda_1}P(t)^{\lambda_2}\)</span><ul><li>其中 <span class="math inline">\(t\)</span> 是中间要生成的词，<span class="math inline">\(\lambda_1\)</span> 表示第一个model，<span class="math inline">\(\lambda_2\)</span> 表示第二个model；<span class="math inline">\(S\)</span> 是source, 个人理解这里为latent state vector(decoder的参数）</li></ul></li></ul></li><li>5.3 Finetune<ul><li>For each sentences in the target dataset, we assume there is a pseudo context; （也就是说，都有一个隐藏的上下文（概率模型），这里有点像VAE)</li></ul></li></ul><h3 id="chapter-6-topic">Chapter 6: Topic</h3><p>Counting Grid(完全不懂…）</p><h2 id="dataset">Dataset</h2><ul><li><a href="http://webscope.sandbox.yahoo.com/%20catalog.php?datatype=l" target="_blank" rel="noopener">Yahoo! Comprehensive Questions and Answers dataset</a> 来做ranking</li><li>Twitter Conversation Dataset（Sordoni et al., 2015）（HERD用的）</li></ul><h2 id="experiment-and-metrics">Experiment and Metrics</h2><p>Ranking problem: MRR P@1</p><p>Style: Human Evaluations</p><figure><img src="http://static.zybuluo.com/Preke/zd7zsvglmpulvy4k9276jjic/image_1cs6k3u35i70163t1hu12qf1b779.png" alt="Ranking result"><figcaption>Ranking result</figcaption></figure><hr><h2 id="acquisition">Acquisition：</h2><p>整体来说，对目前研究的问题帮助不明显，对于模型（encoder-decoder)改进方面有一些数学经验值得借鉴</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;We propose simple and flexible training and decoding methods for &lt;strong&gt;influencing output style a
      
    
    </summary>
    
      <category term="Paper notes" scheme="http://yoursite.com/categories/Paper-notes/"/>
    
    
      <category term="dialog system" scheme="http://yoursite.com/tags/dialog-system/"/>
    
      <category term="conversation generation" scheme="http://yoursite.com/tags/conversation-generation/"/>
    
      <category term="style transfer" scheme="http://yoursite.com/tags/style-transfer/"/>
    
  </entry>
  
  <entry>
    <title>Style Transfer Through Back-Translation</title>
    <link href="http://yoursite.com/2018/11/12/bst/"/>
    <id>http://yoursite.com/2018/11/12/bst/</id>
    <published>2018-11-12T09:17:30.000Z</published>
    <updated>2018-11-13T18:06:06.838Z</updated>
    
    <content type="html"><![CDATA[<h2 id="abstract">Abstract</h2><p>First learn a latent representation of input sentences by NMT model, then use adversarial generation to make the output with desired style.</p><p>Evaluate on three different style transformations:</p><ul><li>sentiment</li><li>gender</li><li>political slant</li></ul><p>Results in:</p><ul><li>automatic evaluation of style transfer</li><li>manual evaluation of meaning preservation and fluency</li></ul><h2 id="contribution">Contribution</h2><ul><li>A new approach to style transfer</li><li>A new task that we propose to evaluate style transfer: transferring politi- cal slant</li></ul><h2 id="methodology">Methodology</h2><p>Given two datasets: <span class="math inline">\(X_1=\{x_1^{(1)},...,x_1^{(n)}\}\)</span> <span class="math inline">\(X_2=\{x_2^{(1)},...,x_2^{(n)}\}\)</span> represent two different styles <span class="math inline">\(s_1\)</span> and <span class="math inline">\(s_2\)</span> (也就是说，所有的<span class="math inline">\(x_1^{(n)}\)</span>的style 都是<span class="math inline">\(s_1\)</span>, 所有的<span class="math inline">\(x_2^{(n)}\)</span>的style 都是<span class="math inline">\(s_2\)</span>)</p><p>Then, generate samples of dataset <span class="math inline">\(X_1\)</span> such that they belong to style <span class="math inline">\(s_2\)</span> and samples of <span class="math inline">\(X_2\)</span> such that they belong to style <span class="math inline">\(s_1\)</span></p><blockquote><p>state-of-the-art</p><ul><li>variational auto-encoders</li><li>cross-aligned autoencoders</li></ul></blockquote><p>aim is to design a latent code <span class="math inline">\(z\)</span>: 1. represents the meaning of the input sentence grounded in back-translation 2. weakens the style attributes of author’s traits</p><h2 id="dataset">Dataset</h2><ul><li>Reddy and Knight’s (2016) dataset of reviews from Yelp annotated for two genders cor- responding to markers of sex.</li><li>comprised of top-level comments on Facebook posts from all 412 current members of the United States Sen- ate and House who have public Facebook pages (Voigt et al., 2018)</li></ul><figure><img src="http://static.zybuluo.com/Preke/mozltnt19hb1zegjijdm3wqk/image_1cs60ditq1v151n5umbgimr95l9.png" alt="Dataset"><figcaption>Dataset</figcaption></figure><h2 id="model-and-experiments">Model and Experiments</h2><figure><img src="http://static.zybuluo.com/Preke/9wlzvypbynyf7buxj6f165m3/image_1cs39rk0g13dka7q7j812vls0g9.png" alt="Style transfer pipeline"><figcaption>Style transfer pipeline</figcaption></figure><figure><img src="http://static.zybuluo.com/Preke/p3fa7ra9emhb721o2sbo6tgt/image_1cs5vrov11tfu1b5p49bkfv1uiap.png" alt="style classifier feedback"><figcaption>style classifier feedback</figcaption></figure><ul><li>CNN去做二分类问题，人工label</li><li>A convolutional neural network (CNN) classifier to accurately predict the given style</li><li>concatenate binary style indicators to each input word embedding in the classifier</li></ul><figure><img src="http://static.zybuluo.com/Preke/4fqmqt59kcva12h34i69rpt5/image_1cs60jlg81stb1tdm1oda1v8ibhup.png" alt="result of classification"><figcaption>result of classification</figcaption></figure><figure><img src="http://static.zybuluo.com/Preke/oau4c5uc3c9aes5fxofkwv81/image_1cs60em6ts2c7sb1bkv12nu18sr16.png" alt="result of human preferance"><figcaption>result of human preferance</figcaption></figure><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;First learn a latent representation of input sentences by NMT model, then use adversarial generation to m
      
    
    </summary>
    
      <category term="Paper notes" scheme="http://yoursite.com/categories/Paper-notes/"/>
    
    
      <category term="dialog system" scheme="http://yoursite.com/tags/dialog-system/"/>
    
      <category term="sentiment" scheme="http://yoursite.com/tags/sentiment/"/>
    
      <category term="Style transfer" scheme="http://yoursite.com/tags/Style-transfer/"/>
    
  </entry>
  
  <entry>
    <title>Sentiment Adaptive End-to-End Dialog Systems</title>
    <link href="http://yoursite.com/2018/11/12/Sentiment_Adaptive_End-to-End_Dialog_Systems/"/>
    <id>http://yoursite.com/2018/11/12/Sentiment_Adaptive_End-to-End_Dialog_Systems/</id>
    <published>2018-11-12T09:17:30.000Z</published>
    <updated>2018-11-13T18:05:56.990Z</updated>
    
    <content type="html"><![CDATA[<h3 id="abstract">Abstract</h3><p>Include user sentiment from <strong>multimodal information(acoustic, dialogic and textual)</strong> in the end-to-end learning framework to make systems <strong>more user-adaptive and effective</strong>.</p><p>First attempt to <strong>incorporate multimodal user information</strong> in the adaptive end-to- end dialog system training framework</p><ul><li>Multimodal Sentiment Classification</li></ul><h3 id="contribution">Contribution</h3><ul><li><a href="https://www.dropbox.com/s/nl5j4ts7kewx47v/sample_50.zip?dl=0" target="_blank" rel="noopener">an audio dataset</a> with sentiment annotation (dialog history)</li><li>an automatic sentiment detector that considers conversation history by using dialogic features, textual features and traditional acoustic features</li><li>end-to-end trainable dialog policies adaptive to user sentiment in both supervised and rein- forcement learning settings</li></ul><h3 id="dataset">Dataset</h3><ul><li><a href="https://www.microsoft.com/en-us/research/event/dialog-state-tracking-challenge/" target="_blank" rel="noopener">DSTC1</a></li><li>人工标注DSTC1的Audio dataset: 50 dialogs consisting of 517 conversation turns for user sentiment (<code>negative</code>, <code>neutral</code> and <code>positive</code>)</li></ul><h3 id="model-and-experiments">Model and Experiments</h3><ul><li>Multimodal Sentiment Classification<ul><li>openSMILE: 提取audio feature</li><li>four categories of dialogic features(人工统计feature)<ul><li>Interruption</li><li>Button usage</li><li>Repetitions</li><li>Start over</li></ul></li><li>Textual features: A <code>tf-idf vector</code> for each utterance as textual features</li></ul></li><li>Classification results<ul><li>Trained on 50 dialogs annotated with sentiment labels<br></li><li>Separated to be 60% for training, 20% for validation and 20% for testing</li><li>run 20 times and get avg</li></ul></li></ul><figure><img src="http://static.zybuluo.com/Preke/r5p3nprhvwb1bzochta2x3y7/image_1cs35h0hp19stdhm10tu1p7rs469.png" alt="image_1cs35h0hp19stdhm10tu1p7rs469.png-50kB"><figcaption>image_1cs35h0hp19stdhm10tu1p7rs469.png-50kB</figcaption></figure><ul><li>Supervised Learning (SL)<ul><li><strong>Detected user sentiment from the previous section</strong> into a supervised learning framework for training end-to-end dialog systems (<strong>classification problem</strong>)</li><li><strong>LSTM with 128 hidden-units and AdaDelta optimizer</strong>(HCN)前人提出的方法，用作baseline，这里的贡献就是加特征 <img src="http://static.zybuluo.com/Preke/18mdpf2tfcf254ulyjb43cla/image_1cs361o15v4u9ob1qo31m061vd8m.png" alt="image_1cs361o15v4u9ob1qo31m061vd8m.png-27.5kB"></li></ul></li></ul><p>Metric 解释：Turn-level F-1 score and dialog accuracy which indicates if all turns in a dialog are correct.</p><ul><li>Reinforcement Learning (RL) (实时从response的sentiment中获取reward, 目的是让response满意）<ul><li>Each turn receives a measurement of goodness called reward</li><li>Include user sentiment as immediate rewards to expedite the reinforcement learning training process</li><li>两个Metric:<ul><li>dialog length: 越小说明完成任务越快</li><li>task success rate: 任务具体如何定义，这里还暂时不太清楚…</li></ul></li></ul></li></ul><figure><img src="http://static.zybuluo.com/Preke/trqn1tlt87jxdztvg3tody61/image_1cs374srqplq71nhf51bh87mo13.png" alt="image_1cs374srqplq71nhf51bh87mo13.png-121.5kB"><figcaption>image_1cs374srqplq71nhf51bh87mo13.png-121.5kB</figcaption></figure><figure><img src="http://static.zybuluo.com/Preke/3hqtlct3wx9ritgzoa9fqggh/image_1cs375eqg1r27ovkci7802mlh1g.png" alt="image_1cs375eqg1r27ovkci7802mlh1g.png-30.7kB"><figcaption>image_1cs375eqg1r27ovkci7802mlh1g.png-30.7kB</figcaption></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;abstract&quot;&gt;Abstract&lt;/h3&gt;
&lt;p&gt;Include user sentiment from &lt;strong&gt;multimodal information(acoustic, dialogic and textual)&lt;/strong&gt; in th
      
    
    </summary>
    
      <category term="Paper notes" scheme="http://yoursite.com/categories/Paper-notes/"/>
    
    
      <category term="dialog system" scheme="http://yoursite.com/tags/dialog-system/"/>
    
      <category term="Multimodal" scheme="http://yoursite.com/tags/Multimodal/"/>
    
  </entry>
  
  <entry>
    <title>奇怪的AEs</title>
    <link href="http://yoursite.com/2018/11/01/AEs/"/>
    <id>http://yoursite.com/2018/11/01/AEs/</id>
    <published>2018-11-01T09:17:30.000Z</published>
    <updated>2018-10-31T16:37:30.562Z</updated>
    
    <content type="html"><![CDATA[<h2 id="autoencoder">AutoEncoder</h2><figure><img src="http://static.zybuluo.com/Preke/f9r48wnmez3um3ci2sxb3tmh/image_1cqnhm30i9d218c3128h1vha7he9.png" alt="AutoEncoder"><figcaption>AutoEncoder</figcaption></figure><p>AutoEncoder直观理解是一个压缩(降维)技术，中间的representation保留了输入的信息，便于decoder去还原信息，训练的loss 则是输入和输出的 MSE(mean-square error)</p><h3 id="useful-links">Useful links:</h3><p>https://towardsdatascience.com/deep-inside-autoencoders-7e41f319999f</p><h2 id="variational-autoencoder">Variational Autoencoder</h2><p>Why VAE: 以下两短话是网上一些博客的解释： &gt; 但是，我们想建一个产生式模型，而不是一个只是储存图片的网络。现在我们还不能产生任何未知的东西，因为我们不能随意产生合理的潜在变量。因为合理的潜在变量都是编码器从原始图片中产生的。<br> 这里有个简单的解决办法。我们可以对编码器添加约束，就是强迫它产生服从单位高斯分布的潜在变量。正式这种约束，把VAE和标准自编码器给区分开来了。<br> 现在，产生新的图片也变得容易：我们只要从单位高斯分布中进行采样，然后把它传给解码器就可以了。</p><hr><blockquote><p>但是这样我们其实并不能任意生成图片，因为我们没有办法自己去构造隐藏向量，我们需要通过一张图片输入编码我们才知道得到的隐含向量是什么，这时我们就可以通过变分自动编码器来解决这个问题。<br> 其实原理特别简单，只需要在编码过程给它增加一些限制，迫使其生成的隐含向量能够粗略的遵循一个标准正态分布，这就是其与一般的自动编码器最大的不同。<br> 这样我们生成一张新图片就很简单了，我们只需要给它一个标准正态分布的随机隐含向量，这样通过解码器就能够生成我们想要的图片，而不需要给它一张原始图片先编码。</p></blockquote><p>如何理解中间的潜在向量服从高斯分布呢？又如何理解采样的过程呢？ 看到一个博客里的一张图可以比较简单的理解： <img src="http://static.zybuluo.com/Preke/i4633iw9mjxb27geln7cxg1u/image_1cr5aotjkb1didtqas1i1uoge9.png"></p><p>也就是每个输入样本输入后，会产生:</p><ul><li>一个均值的representation</li><li>一个方差的representation</li></ul><p>那么这里的均值是谁的均值，方差又是谁的方差呢？ 联想到和VAE有点像的GAN, 如果输入样本本身就是一个分布的话， 那么这个均值和方差就是输入样本的均值和方差 如果是这样的话，如何约束他们服从一个正态分布呢？ 我想这里就是encoder部分所做的约束</p><p><img src="http://static.zybuluo.com/Preke/nyzp95bo8lljrwhqnpgeujl5/image_1cr5e33e3188nsclsassl100r9.png"></p><h3 id="误差">误差</h3><p>对于AE来说，误差其实就是原始信息（图片)和生成信息(图片）之间的MSE （重构误差） 那么VAE在训练的时候，除了重构误差之外，其实还有每个样本的分布和标准正态分布之间的KL散度；</p><h3 id="理解">理解：</h3><p>经过看完这些材料，理解完上述的东西，用自己的话说：</p><p>我有一些样本，我假设每个样本都是服从一个正态分布的，可是我们不知道这个分布。 VAE试图去估计每个样本背后分布的均值和方差，并且进行采样，对每个样本得到一个隐层表示向量，然后通过这个向量去生成新的样本； 通过生成样本和原有样本的对比误差，以及中间估计的分布与标准正态分布的KL散度，去修正参数，使得：</p><p>VAE生成的样本是具有原有样本的“灵魂”而又不完全相同的样本 （好吧，这是一句没有灵魂的话）</p><h3 id="why-vae-again">Why VAE again：</h3><p>还是引用大佬们的话吧, 我觉得是我能读懂并且可以接受的： <img src="http://static.zybuluo.com/Preke/shxs61d5xpwo4iw4i3sebxdz/image_1cr5eqlh01kgu1qpbjll1ln715n8m.png" alt="image_1cr5eqlh01kgu1qpbjll1ln715n8m.png-177.8kB"></p><h3 id="useful-links-1">Useful links:</h3><p>墙裂推荐以下链接的文章，真的写的很好，（大部分我都是引用于此的）….</p><p>https://www.cnblogs.com/huangshiyu13/p/6209016.html<br> https://zhuanlan.zhihu.com/p/27549418<br> https://zhuanlan.zhihu.com/p/34998569</p><h2 id="cvae">CVAE</h2><p>这个部分称为Conditional VAE</p><p>无论是AE, 还是VAE，任务都是去拟合，去生成， 都是没有用到一些label信息去做分类的</p><h3 id="useful-links-2">Useful links:</h3><p>https://zhuanlan.zhihu.com/p/34998569</p><h2 id="ae-s2s">AE &amp; S2S</h2><h2 id="vae-for-nlp">VAE for NLP</h2>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;autoencoder&quot;&gt;AutoEncoder&lt;/h2&gt;
&lt;figure&gt;
&lt;img src=&quot;http://static.zybuluo.com/Preke/f9r48wnmez3um3ci2sxb3tmh/image_1cqnhm30i9d218c3128h
      
    
    </summary>
    
      <category term="Deep learning" scheme="http://yoursite.com/categories/Deep-learning/"/>
    
    
      <category term="AE" scheme="http://yoursite.com/tags/AE/"/>
    
      <category term="VAE" scheme="http://yoursite.com/tags/VAE/"/>
    
      <category term="CVAE" scheme="http://yoursite.com/tags/CVAE/"/>
    
      <category term="S2S" scheme="http://yoursite.com/tags/S2S/"/>
    
  </entry>
  
  <entry>
    <title>MOJITALK Generating Emotional Responses at Scale</title>
    <link href="http://yoursite.com/2018/10/22/Scale/"/>
    <id>http://yoursite.com/2018/10/22/Scale/</id>
    <published>2018-10-22T09:17:30.000Z</published>
    <updated>2018-12-17T06:56:48.420Z</updated>
    
    <content type="html"><![CDATA[]]></content>
    
    <summary type="html">
    
      
      
        

      
    
    </summary>
    
      <category term="Paper notes" scheme="http://yoursite.com/categories/Paper-notes/"/>
    
    
      <category term="emotion" scheme="http://yoursite.com/tags/emotion/"/>
    
      <category term="dialog system" scheme="http://yoursite.com/tags/dialog-system/"/>
    
  </entry>
  
  <entry>
    <title>恰同学少年</title>
    <link href="http://yoursite.com/2018/10/21/%E6%81%B0%E5%90%8C%E5%AD%A6%E5%B0%91%E5%B9%B4/"/>
    <id>http://yoursite.com/2018/10/21/恰同学少年/</id>
    <published>2018-10-21T15:31:37.000Z</published>
    <updated>2018-10-21T15:45:00.636Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>独立寒秋，湘江北去，橘子洲头。 看万山红遍，层林尽染；漫江碧透，百舸争流。 鹰击长空，鱼翔浅底，万类霜天竞自由。 怅寥廓，问苍茫大地，谁主沉浮？ 携来百侣曾游。忆往昔峥嵘岁月稠。 恰同学少年，风华正茂；书生意气，挥斥方遒。 指点江山，激扬文字，粪土当年万户侯。 曾记否，到中流击水，浪遏飞舟？</p></blockquote><p>就突然想到小时候看的电视剧《恰同学少年》，当时爷爷还给我讲过那些蔡和森的故事；爷爷去世很多年了，这也是为数不多的我关于他的记忆了。</p><p>谁年轻的时候不是粪土当年万户侯？ 遇到社会矛盾，谁又不是针砭时弊，痛斥当权者？</p><p>以前我相信，这些肉食者思想固化，跟不上时代；等我们这一代人当权，必能改变世界，必能大有作为。 可是几千年来，哪个时代的热血青年不是如此想的呢？ 江山易主，旧历史总会重复 朝代更迭，新矛盾总会出现 各国各时代又有何区别？ 权力集中的地方必然有腐败，矛盾出现时一定要有人负责； 如何去和人性做抗争呢？ 毛泽东尚有 驱张行动，愤青们的不理智谁又能买单呢？</p><p>然而，愤青好就好在有一群人坚持自己的信念， 信念可能很不现实，但是一群人依然坚信 再困难，再失落，总有人鼓励 一起奋斗，是只有青春才能迸发的激情</p><p>恰同学少年，风华正茂；书生意气，挥斥方遒。 指点江山，激扬文字，粪土当年万户侯</p><p>青春而又豪迈</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;独立寒秋，湘江北去，橘子洲头。 看万山红遍，层林尽染；漫江碧透，百舸争流。 鹰击长空，鱼翔浅底，万类霜天竞自由。 怅寥廓，问苍茫大地，谁主沉浮？ 携来百侣曾游。忆往昔峥嵘岁月稠。 恰同学少年，风华正茂；书生意气，挥斥方遒。 指点江山，激扬文字，粪土
      
    
    </summary>
    
      <category term="随感" scheme="http://yoursite.com/categories/%E9%9A%8F%E6%84%9F/"/>
    
    
  </entry>
  
  <entry>
    <title>三尺微命，一介书生</title>
    <link href="http://yoursite.com/2018/10/20/%E4%B8%89%E5%B0%BA%E5%BE%AE%E5%91%BD,%E4%B8%80%E4%BB%8B%E4%B9%A6%E7%94%9F/"/>
    <id>http://yoursite.com/2018/10/20/三尺微命,一介书生/</id>
    <published>2018-10-19T16:00:00.000Z</published>
    <updated>2018-10-26T06:32:40.891Z</updated>
    
    <content type="html"><![CDATA[<p>也是大四几个人在喝酒吹牛，</p><p>聊到各自的不得志，</p><p>醉醺醺的最先想到的就是《滕王阁序》</p><p>于是便有人慷慨激昂：穷且益坚，不坠青云之志</p><p>高二初读《滕王阁序》，印象十分深刻，</p><p>可能就是本身喜欢骈文，读起来气势恢宏，朗朗上口</p><p>然而其中意境，十不能明一二</p><p>但是读到这句话，真的分量很重，很能切身感受到郁郁不得志的心情</p><blockquote><p>勃，三尺微命，一介书生<br>无路请缨，等终军之弱冠<br>有怀投笔，慕宗悫之长风</p></blockquote><p>对照注释中的愿乘长风破万里浪，哪个意气风发的少年不识如此呢？</p><p>何况初唐四杰之首，天妒英才的王勃呢</p><p>就算是平庸的自己，读到此处也很容易就被代入到才华横溢，壮志难酬的作者当中去</p><p>眼神望去天边的晚霞，有年少时的才华横溢，有不尽的赏识和艳羡，有官场失足的困顿，也有受到连累困苦的父亲</p><p>从文章本身去想：前面引经据典，信手拈来，意境华丽，恢弘壮阔</p><p>转而 关山难越，谁悲失路之人；萍水相逢，尽是他乡之客</p><p>继而 孟尝高洁，空余报国之情；阮籍猖狂，岂效穷途之哭</p><p>竟是对比强烈，让人慨叹</p><p>我也不知道我为什么会喜欢上这句话，</p><p>或许是很能对照我们比较大众的现状：能力和才华，配不上自己的野心</p><p>亦或许是对自己的安慰，我不想给自己承担太多，仅仅是三尺微命，一介书生</p><p>三尺微命啊三尺微命</p><p>十人有九堪白眼的三尺微命</p><p>一介书生啊一介书生</p><p>饮冰十年难凉热血的一介书生</p><p>亦不是说每个人心中都有难酬的壮志</p><p>只是没到满足于老婆孩子热坑头的年龄</p><p>面对现实，总会觉得渺小，觉得心有余而力不足</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;也是大四几个人在喝酒吹牛，&lt;/p&gt;
&lt;p&gt;聊到各自的不得志，&lt;/p&gt;
&lt;p&gt;醉醺醺的最先想到的就是《滕王阁序》&lt;/p&gt;
&lt;p&gt;于是便有人慷慨激昂：穷且益坚，不坠青云之志&lt;/p&gt;
&lt;p&gt;高二初读《滕王阁序》，印象十分深刻，&lt;/p&gt;
&lt;p&gt;可能就是本身喜欢骈文，读起来气势恢宏，
      
    
    </summary>
    
      <category term="随感" scheme="http://yoursite.com/categories/%E9%9A%8F%E6%84%9F/"/>
    
    
  </entry>
  
  <entry>
    <title>《射雕》的一点印象</title>
    <link href="http://yoursite.com/2018/08/26/%E3%80%8A%E5%B0%84%E9%9B%95%E3%80%8B%E7%9A%84%E4%B8%80%E7%82%B9%E5%8D%B0%E8%B1%A1/"/>
    <id>http://yoursite.com/2018/08/26/《射雕》的一点印象/</id>
    <published>2018-08-26T08:46:22.000Z</published>
    <updated>2018-10-22T07:03:21.296Z</updated>
    
    <content type="html"><![CDATA[<p>这几天花了好久时间去看射雕，也算是Kindle没白费。</p><p>《射雕》给我的几个印象是：</p><ol type="1"><li>为了造成冲突，上来就打，混不解释；如桃花岛上江南五怪被杀，黄蓉看到种种线索，心中推测的疑点也不说出，任郭靖独自乘船离开；郭靖也是，啥都不清楚，就认准了黄老邪，对蓉儿也是瞬间色变；如黄老邪愣是心高气傲，不解释不开脱自己没杀江南五怪；又如轩辕台上，郭靖脱身的第一反应是先打个痛快，打了好久才让黄蓉道出真相；种种情结真是让人读的时候，皇上不急太监急。</li><li>人物不立体（不过这个金老先生也在后记中说到了，脸谱化，春秋笔法）。</li><li>郭靖开挂太明显：傻头傻脑，蒙古大汗儿子结拜，女儿许配，拜江南七怪，8岁杀陈玄风，得马钰传内功，得唯一的汗血宝马和双雕，喝蛇血百毒不侵，洪七公教降龙十八掌，周伯通教九阴真经和一心二用，还有黄蓉倾心（死心塌地，不离不弃的倾心，我觉得这个是最大的开挂！）；因为之前看过《天龙八部》，混觉得郭靖简直就是虚竹和萧峰的合体。</li><li>巧巧巧，也所谓无巧不成书；无论是大漠草原，太湖陆家庄，小小牛家村一间小屋，各路豪杰都能聚齐；</li><li>书中各种唱词，真是美如画，金庸融进来的道家文化和宋词文化十分丰富。</li><li>民族大义，倒是很像《天龙八部》；无论是郭靖，杨康，还是乔峰，是生我的祖先父辈的国家是祖国，还是养我的国家是祖国呢？郭靖是和黄蓉一起了解了岳爷爷的历史，了解了韩世忠，上官剑南等忠义之士的事迹，才会力保武穆遗书；听蓉儿讲了各种唱词，以及词中的故事，才会对大宋有了文化认同吧。这些杨康有吗？他成年之时也是大金国的小王爷，接触的全是大金的民族教育和文化认同，他没有太多的culture shock，也不易改变；不过让他坚定决心的就是祠堂中完颜洪烈对他说以后富贵不可限量。</li><li>铁木真，还真的就像《天龙八部》的耶律洪基。</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;这几天花了好久时间去看射雕，也算是Kindle没白费。&lt;/p&gt;
&lt;p&gt;《射雕》给我的几个印象是：&lt;/p&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;为了造成冲突，上来就打，混不解释；如桃花岛上江南五怪被杀，黄蓉看到种种线索，心中推测的疑点也不说出，任郭靖独自乘船离开；郭靖也是，啥
      
    
    </summary>
    
      <category term="随感" scheme="http://yoursite.com/categories/%E9%9A%8F%E6%84%9F/"/>
    
    
  </entry>
  
  <entry>
    <title>马云的年会演讲</title>
    <link href="http://yoursite.com/2017/09/12/%E9%A9%AC%E4%BA%91%E7%9A%84%E5%B9%B4%E4%BC%9A%E6%BC%94%E8%AE%B2/"/>
    <id>http://yoursite.com/2017/09/12/马云的年会演讲/</id>
    <published>2017-09-12T08:46:22.000Z</published>
    <updated>2018-10-20T15:17:36.793Z</updated>
    
    <content type="html"><![CDATA[<p>今儿看了马云的年会演讲</p><p>感触很深就是，阿里是一个最强调社会责任感的公司了。也许跟他的愿景有关</p><p><strong>让天下没有难做的生意</strong></p><p>马云不是一个做技术的，所以决定了阿里不是一个纯技术公司</p><p>去各个大学演讲，与特朗普谈话承诺就业岗位，出席达沃斯，马云俨然是一个经济体的领头人。</p><p>演讲中提到了不作恶，当然这是Google的信条，我猛一想，去年Google 也18岁了，好像没见拉里佩奇演讲啊…</p><p>腾讯去年总办发红包…小马哥也没有强调什么，要做中国人沟通的桥梁类似的话…</p><p>所以我觉得，明年的百度？似乎能看到robin 吹一波人工智能对未来，对现在的影响，百度其实也承担了挺多的社会责任的</p><p>回归正题呢，我觉得马云提出的，服务农村，消除贫困，全球化等等未来的方向，这不是政府的工作吗？阿里可能是不那么独立的公司(没说不是好事)，为政府服务，为社会服务，反过来，政府也提供充分的资源，社会资源。是一个良好的合作关系。这个公司的发展和社会的进步相得益彰，也是一种独特的模式</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;今儿看了马云的年会演讲&lt;/p&gt;
&lt;p&gt;感触很深就是，阿里是一个最强调社会责任感的公司了。也许跟他的愿景有关&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;让天下没有难做的生意&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;马云不是一个做技术的，所以决定了阿里不是一个纯技术公司&lt;/p&gt;
&lt;p&gt;去各个大学演
      
    
    </summary>
    
      <category term="随感" scheme="http://yoursite.com/categories/%E9%9A%8F%E6%84%9F/"/>
    
    
  </entry>
  
</feed>
