<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="en">
<head><meta name="generator" content="Hexo 3.9.0">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT">





  <link rel="alternate" href="/atom.xml" title="Zhiyuan" type="application/atom+xml">






<meta name="description" content="三尺微命，一介书生">
<meta property="og:type" content="website">
<meta property="og:title" content="Zhiyuan">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="Zhiyuan">
<meta property="og:description" content="三尺微命，一介书生">
<meta property="og:locale" content="en">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Zhiyuan">
<meta name="twitter:description" content="三尺微命，一介书生">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5.1.4',
    sidebar: {"position":"left","display":"always","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/">





  <title>Zhiyuan</title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Zhiyuan</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">三尺微命，一介书生</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/07/09/acl_2019/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Zhiyuan">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/Gold.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhiyuan">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/07/09/acl_2019/" itemprop="url">ACL 2019 一些感兴趣的paper</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-07-09T17:17:30+08:00">
                2019-07-09
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Paper-notes/" itemprop="url" rel="index">
                    <span itemprop="name">Paper notes</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>不久前放出了ACL2019的paper list, 但是还没有具体的文章，这里立一些flag, 找一些感兴趣的paper来读。</p>
<h2 id="text-style-transfer">Text style transfer</h2>
<p><strong><em>Towards Fine-grained Text Sentiment Transfer</em></strong> Fuli Luo, Peng Li, Pengcheng Yang, Jie Zhou, Yutong Tan, Baobao Chang, Zhifang Sui and Xu SUN</p>
<p>这个跟我之前做的问题比较像，比较感兴趣…</p>
<p><strong><em>A Hierarchical Reinforced Sequence Operation Method for Unsupervised Text Style Transfer</em></strong> Chen Wu, Xuancheng Ren, Fuli Luo and Xu SUN</p>
<h2 id="open-domain-dialog-system-text-generation">Open-domain Dialog System &amp; Text Generation</h2>
<h3 id="emotion">Emotion</h3>
<p><strong><em>Generating Responses with a Specific Emotion in Dialog</em></strong> Zhenqiao Song, Xiaoqing Zheng, Lu Liu, Mu Xu and Xuanjing Huang</p>
<p>这个很直接的老问题…不知道为什么还被录，可能是效果确实很牛或者模型很新吧..</p>
<p><strong><em>Towards Empathetic Open-domain Conversation Models: a New Benchmark and Dataset</em></strong> Hannah Rashkin, Eric Michael Smith, Margaret Li and Y-Lan Boureau</p>
<p>这个像是一个开坑的工作…虽然 Empathetic computing 之前也有一些work, 但是不知道 ACL 为什么今年只有一篇…</p>
<p><strong><em>Adversarial Attention Modeling for Multi-dimensional Emotion Regression</em></strong> Suyang Zhu, Shoushan Li and Guodong Zhou</p>
<p>Emotion Regression 可以科普一下</p>
<p><strong><em>Divide, Conquer and Combine: Hierarchical Feature Fusion Network with Local and Global Perspectives for Multimodal Affective Computing</em></strong> Sijie Mai, Haifeng Hu and Songlong Xing</p>
<p>Affective Computing的</p>
<p><strong><em>Entity-Centric Contextual Affective Analysis</em></strong> Anjalie Field and Yulia Tsvetkov</p>
<p>Affective Computing的</p>
<h3 id="personalization">Personalization</h3>
<p><strong><em>Persuasion for Good: Towards a Personalized Persuasive Dialogue System for Social Good</em></strong> Xuewei Wang, Weiyan Shi, Richard Kim, Yoojung Oh, Sijia Yang, Jingwen Zhang and Zhou Yu</p>
<p>特殊场景？</p>
<p><strong><em>Personalizing Dialogue Agents via Meta-Learning</em></strong> Andrea Madotto, Zhaojiang Lin, Chien-Sheng Wu and Pascale Fung</p>
<p>Meta-learning没了解过，通过这个科普一下</p>
<p><strong><em>Automatic Generation of Personalized Comment Based on User Profile</em></strong> Wenhuan Zeng, Abulikemu Abuduweili, Lei Li and Pengcheng Yang</p>
<p>可以看一下是如何利用 User Profile 的</p>
<p><strong><em>Incorporating Textual Information on User Behavior for Personality Prediction</em></strong> Kosuke Yamada, Ryohei Sasano and Koichi Takeda</p>
<p>关于心理学定义的人格的paper感觉都可以关注一下…</p>
<h3 id="others">Others</h3>
<p><strong><em>Semantically Conditioned Dialog Response Generation via Hierarchical Disentangled Self-Attention</em></strong> Wenhu Chen, Jianshu Chen, Pengda Qin, Xifeng Yan and William Yang Wang</p>
<p>William Yang Wang在微博上推广过这个…</p>
<p><strong><em>Learning from Dialogue after Deployment: Feed Yourself, Chatbot!</em></strong> Braden Hancock, Antoine Bordes, Pierre-Emmanuel Mazare and Jason Weston</p>
<p>看标题像是一个online-learning的问题</p>
<p><strong><em>Dialogue Natural Language Inference</em></strong> Sean Welleck, Jason Weston, Arthur Szlam and Kyunghyun Cho</p>
<p>这个title, 结合了不知道什么意思</p>
<p><strong><em>Are Training Samples Correlated? Learning to Generate Dialogue Responses with Multiple References</em></strong> Lisong Qiu, Juntao Li, Wei Bi, Dongyan Zhao and Rui Yan</p>
<p>看起来像是一个Grounding的问题</p>
<p><strong><em>Pretraining Methods for Dialog Context Representation Learning</em></strong> Shikib Mehri, Evgeniia Razumovskaia, Tiancheng Zhao and Maxine Eskenazi</p>
<p>问题很感兴趣，应用场景应该是多轮对话吧</p>
<p><strong><em>Self-Supervised Dialogue Learning</em></strong> Jiawei Wu, Xin Wang and William Yang Wang</p>
<p>自监督？</p>
<p><strong><em>Domain Adaptive Dialog Generation via Meta Learning</em></strong> Kun Qian and Zhou Yu</p>
<p>每个名词都很感兴趣…</p>
<p><strong><em>Know More about Each Other: Evolving Dialogue Strategy via Compound Assessment</em></strong> Siqi Bao, Huang He, Fan Wang, Rongzhong Lian and Hua Wu</p>
<p>关于策略的也很感兴趣，看是如何用其他Knowledge</p>
<p><strong><em>Do Neural Dialog Systems Use the Conversation History Effectively? An Empirical Study</em></strong> Chinnadhurai Sankar, Sandeep Subramanian, Chris Pal, Sarath Chandar and Yoshua Bengio</p>
<p>多轮对话？Bengio？</p>
<p><strong><em>Boosting Dialog Response Generation</em></strong> Wenchao Du and Alan W Black</p>
<p>Boosting有点意思…</p>
<p><strong><em>Implicit Discourse Relation Identification for Open-domain Dialogues</em></strong> Mingyu Derek Ma, Kevin Bowden, Jiaqi Wu, Wen Cui and Marilyn Walker</p>
<p>这个一作好像认识…</p>
<p><strong><em>ConvLab: Multi-Domain End-to-End Dialog System Platform</em></strong> Sungjin Lee, Qi Zhu, Ryuichi Takanobu, Xiang Li, Yaoqin Zhang, Zheng Zhang, Jinchao Li, Baolin Peng, Xiujun Li, Minlie Huang and Jianfeng Gao</p>
<p>感兴趣 Multi-Domain</p>
<p><strong><em>ADVISER: A Dialog System Framework for Education &amp; Research Daniel Ortega, Dirk Väth, Gianna Weber, Lindsey Vanderlyn, Maximilian</em></strong> Schmidt, Moritz Völkel, Zorica Karacevic and Ngoc Thang Vu</p>
<p>特定应用场景</p>
<p><strong><em>Dialogue-Act Prediction of Future Responses based on Conversation History</em></strong> Koji Tanaka, Junya Takayama and Yuki Arase</p>
<p>Prediction 感兴趣</p>
<p><strong><em>Vocabulary Pyramid Network: Multi-Pass Encoding and Decoding with Multi-Level Vocabularies for Response Generation</em></strong> Cao Liu, Shizhu He, Kang Liu and Jun Zhao</p>
<p>刘康老师的work呀</p>
<p><strong><em>Learning to Abstract for Memory-augmented Conversational Response Generation</em></strong> Zhiliang Tian, Wei Bi, Xiaopeng Li and Nevin L. Zhang</p>
<p>Memory-augmented感兴趣</p>
<p><strong><em>Neural Response Generation with Meta-words</em></strong> Can Xu, wei wu, Chongyang Tao, Huang Hu, Matt Schuerman and Ying Wang</p>
<p>Meta-words很感兴趣</p>
<p><strong><em>OpenDialKG: Explainable Conversational Reasoning with Attention-based Walks over Knowledge Graphs</em></strong> Seungwhan Moon, Pararth Shah, Anuj Kumar and Rajen Subba</p>
<p>和Knowledge graph的结合</p>
<p><strong><em>E3: Entailment-driven Extracting and Editing for Conversational Machine Reading</em></strong> Victor Zhong and Luke Zettlemoyer</p>
<p><strong><em>Interconnected Question Generation with Coreference Alignment and Conversation Flow Modeling</em></strong> Yifan Gao, Piji Li, Irwin King and Michael R. Lyu</p>
<p><strong><em>Proactive Human-Machine Conversation with Explicit Conversation Goal</em></strong> Wenquan Wu, Zhen Guo, Xiangyang Zhou, Hua Wu, Xiyuan Zhang, Rongzhong Lian and Haifeng Wang</p>
<p><strong><em>Fine-Grained Sentence Functions for Short-Text Conversation</em></strong> Wei Bi, Jun Gao, Xiaojiang Liu and Shuming Shi</p>
<p><strong><em>Target-Guided Open-Domain Conversation</em></strong> Jianheng Tang, Tiancheng Zhao, Chenyan Xiong, Xiaodan Liang, Eric Xing and Zhiting Hu</p>
<p><strong><em>Microsoft Icecaps: An Open-Source Toolkit for Conversation Modeling</em></strong> Vighnesh Leonardo Shiv, Chris Quirk, Anshuman Suri, Xiang Gao, Khuram Shahid, Nithya Govindarajan, Yizhe Zhang, Jianfeng Gao, Michel Galley, Chris Brockett, Tulasi Menon and Bill Dolan</p>
<p>小冰升级了么…</p>
<p><strong><em>Sentence Level Curriculum Learning for Improved Neural Conversational Models</em></strong> Sean Paulsen</p>
<p>Curriculum Learning很感兴趣</p>
<h2 id="general-nlp">General NLP</h2>
<p><strong><em>Towards Explainable NLP: A Generative Explanation Framework for Text Classification</em></strong> Hui Liu, Qingyu Yin and William Yang Wang</p>
<p>这个看标题挺厉害的…</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/07/08/xiaobing/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Zhiyuan">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/Gold.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhiyuan">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/07/08/xiaobing/" itemprop="url">小冰如何生成个性化回复</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-07-08T08:46:22+08:00">
                2019-07-08
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Paper-notes/" itemprop="url" rel="index">
                    <span itemprop="name">Paper notes</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>小冰被设计为一个18岁的女孩，可靠，富有同情，感性而幽默。</p>
<blockquote>
<p>The XiaoIce persona is designed as a 18-year-old girl who is always reliable, sympathetic, affectionate, and has a wonderful sense of humor.</p>
</blockquote>
<p>那这些属性在生成回复的时候如何产生影响呢？ 这里就涉及到两个模块：Empathetic Computing 和 Core Chat</p>
<h2 id="empathetic-computing">Empathetic Computing</h2>
<p>这部分包括：</p>
<ul>
<li>Contextual Query Understanding</li>
<li>User Understanding</li>
<li>Interpersonal Response Generation</li>
</ul>
<h3 id="contextual-query-understanding">Contextual Query Understanding</h3>
<p>这一部分就可以理解为是根据上下文进行query expansion, 做一些指代消歧，上下文补充等。 总的来说就是对输入query <span class="math inline">\(Q\)</span>, 结合上下文 <span class="math inline">\(C\)</span> (历史会话信息），生成带有上下文信息的query <span class="math inline">\(Q_c\)</span>:</p>
<p><span class="math display">\[
Q_c = f_{cqu}(Q, C)
\]</span></p>
<h3 id="user-understanding">User Understanding</h3>
<p>这一部分是根据上下文 <span class="math inline">\(C\)</span> 和 query <span class="math inline">\(Q_c\)</span> 生成用户的信息 <span class="math inline">\(e_Q\)</span>，是一个用户共情向量，包括用户的属性信息（如果有的话），对话的topic, intent；也还包括emotion 和 sentiment的分析；<span class="math inline">\(e_Q\)</span>就如下图（一直用neural来表示中立，不知道是不是typo…)：</p>
<figure>
<img src="https://upload-images.jianshu.io/upload_images/2675254-09a2c70e80ce9bca.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><figcaption>image.png</figcaption>
</figure>
<p>形式化就是：</p>
<p><span class="math display">\[
e_Q = f_{uu}(Q_c, C)
\]</span></p>
<h3 id="interpersonal-response-generation">Interpersonal Response Generation</h3>
<p>这一部分是通过<span class="math inline">\(e_Q\)</span>中的会话信息和小冰预设的 persona profile (key-value pairs) 生成一个回复共情向量<span class="math inline">\(e_R\)</span>:</p>
<figure>
<img src="https://upload-images.jianshu.io/upload_images/2675254-129d192aff85f8f5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image1.png"><figcaption>image1.png</figcaption>
</figure>
<p>形式化就是：</p>
<p><span class="math display">\[
e_R = f_{irg}(e_R, Persona\  profile\  of \ Xiaoice)
\]</span></p>
<h2 id="core-chat">Core Chat</h2>
<p>有了上述的 <span class="math inline">\(\{Q_c, C, e_Q, e_R\}\)</span> 之后，在这部分结合这些信息生成回复。我这里只比较关系如何用generation-based方法去生成，如下图所示：</p>
<figure>
<img src="https://upload-images.jianshu.io/upload_images/2675254-ce68704903dae579.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><figcaption>image.png</figcaption>
</figure>
<p>模型基于RNN的seq2seq model, 将 <span class="math inline">\(Q_c\)</span> 作为 encoder的输入，得到hidden state vector再输入到decoder; 而在解码每个词的时候，都是通过一个包含了<span class="math inline">\(e_Q, e_R\)</span> 信息的向量 <span class="math inline">\(v\)</span> 去加入上下文和小冰的属性信息；而这个 <span class="math inline">\(v\)</span> 是通过如下公式来得到：</p>
<p><span class="math display">\[
v = \sigma (W^T_Qe_Q + W^T_Re_R)
\]</span></p>
<p>（我猜想每次结合的方式就是 <span class="math inline">\(v\)</span> 和 当前输入词向量<span class="math inline">\(e_t\)</span> concat一起之后再过一个线性层去规范维度</p>
<hr>
<p>通过以上这两个部分，小冰就能生成个性化的回复； 其实还是有两个点比较简单：</p>
<ol type="1">
<li>对于属性的描述，用了很简单的key-value直接输入，对于具体属性如何影响回复生成并没有更深的modeling;</li>
<li>属性的表达上，其实也是比较简单的作用在了每次解码结合同样的信息，参考Emotional Chatting Machine这篇paper的思路的话，其实表达方式上，也是有一些多变的因素的。</li>
</ol>
<p>当然，可能具体使用上没办法去部署比较复杂的模型，也可能是因为小冰的数据足够多，而且其实大部分都还是用检索式，所以整体呈现的效果还确实不错~</p>
<h2 id="ref">Ref:</h2>
<p>Zhou L, Gao J, Li D, et al. The design and implementation of XiaoIce, an empathetic social chatbot[J]. arXiv preprint arXiv:1812.08989, 2018.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/07/04/Mul_response/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Zhiyuan">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/Gold.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhiyuan">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/07/04/Mul_response/" itemprop="url">Generating Multiple Diverse Responses for Short-Text Conversation</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-07-04T08:46:22+08:00">
                2019-07-04
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Paper-notes/" itemprop="url" rel="index">
                    <span itemprop="name">Paper notes</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Paper链接: https://arxiv.org/abs/1811.05696</p>
<p>腾讯AI Lib的一篇paper, 发在 AAAI2019, 主要是解决对话中“一对多”的问题</p>
<p>目前我们做对话生成的模型大多都是基于seq2seq, 因为在 machine translation or text summarization 的任务中，文本生成的效果确实不错。 但是本质上，seq2seq是一个“一对一”的问题，然而对话，可能存在一个post，多种回复（语义不相同，没有词overlap)都是合适的。退一步讲，我们经常用的对话数据如微博, twitter，这些数据本身也是一对多（多条评论）的。</p>
<h3 id="problem-formulation">Problem formulation</h3>
<p>训练数据为 <span class="math inline">\(\{ (x, \{ y \} )\}\)</span>, 即给定一个query <span class="math inline">\(x\)</span>, 目标是去生成一个responses的集合 <span class="math inline">\(\{ y \}\)</span>, 通过引入一个中间变量 <span class="math inline">\(z\)</span> 建立 <span class="math inline">\(x\)</span> 和 $ { y } $ 的联系; 具提来说是去最小化loss:</p>
<p><span class="math display">\[
 J(\theta) = \mathcal L( \{ y \}| x) = \mathbf E_{p(z|x) }[\mathcal L(\{y\}|x,z)]
\]</span></p>
<p>而中间这个 <span class="math inline">\(z\)</span> , 作者是用一些采样出来的words来表示的。相应的，<span class="math inline">\(p(z|x)\)</span> 就是words 的 distribution. 作者用了一个一个双向 GRU 来 encode <span class="math inline">\(x\)</span> to <span class="math inline">\(h_x\)</span>, 再过一个softmax去算<span class="math inline">\(z\)</span> 的概率分布，就像一个简单的分类器：</p>
<p><span class="math display">\[
p(z|x) = softmax(W_2 \cdot tanh(W_1h_x + b_1) + b_2)
\]</span></p>
<p>这个中间变量 <span class="math inline">\(z\)</span> 应该遵循</p>
<ul>
<li>可解释性：能解释与 <span class="math inline">\(x\)</span> 和 $ { y } $ 的联系</li>
<li>有区分度， 不同的 <span class="math inline">\(x\)</span> 应该产生不同的 <span class="math inline">\(z\)</span></li>
</ul>
<blockquote>
<p>虽然用采样出来的 words 能够满足这两点，但还是不很理解为什么用 words 作为中间变量，离散的words相当于割裂了两部分，直接用分布不好吗？去掉中间的采样过程？</p>
</blockquote>
<p>而对于 <span class="math inline">\(\mathcal L(\{y\}|x,z)\)</span>, 由于是估计多个 <span class="math inline">\(\mathbf y\)</span>, 那么作者做了一个简单的架设，用一个可微的函数 <span class="math inline">\(f\)</span> 把预测单个 <span class="math inline">\(\mathbf y\)</span> 的估计联合在了一起： <span class="math display">\[
\mathcal L(\{y\}|x,z) = f_{\mathbf y\in\{y\}}(\mathcal l(\mathbf y|x, z))
\]</span></p>
<h3 id="model">Model</h3>
<p>模型架构如下：</p>
<figure>
<img src="https://upload-images.jianshu.io/upload_images/2675254-9f6ba40e800dfdab.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><figcaption>image.png</figcaption>
</figure>
<p>每次估计单个 <span class="math inline">\(\mathbf y\)</span> 的时候， 作者每一步将</p>
<ul>
<li>当前步骤的 hidden states <span class="math inline">\(h_y(t)\)</span></li>
<li><span class="math inline">\(x\)</span> 和 <span class="math inline">\(z\)</span> 的attention</li>
<li>解码过程 <span class="math inline">\(h_{\mathbf y}(t)\)</span> 和 <span class="math inline">\(x\)</span> 的 attention</li>
</ul>
<p>结合在一起去解码每一个词。</p>
<p>至于可微函数 <span class="math inline">\(f\)</span>, 考虑到多个 <span class="math inline">\(\mathbf y\)</span> 中，与 之前的 $ z $ 最相关的<span class="math inline">\(\mathcal L(\{y\}|x,z)\)</span> 应该最小，所以，这个 <span class="math inline">\(f\)</span> 就简单采用了 min函数：</p>
<p><span class="math display">\[
f(\{y\}|x,z) = \min_{\mathbf y \in \{ y\}} \mathcal l(\mathbf y |x, z)
\]</span></p>
<h3 id="training-with-rl">Training with RL</h3>
<p>前半部分 Modeling <span class="math inline">\(p(z|x)\)</span>, 是一个典型的生成词 (采样词) 的过程，作者这里用了RL里面的Policy Gradient去优化这个过程;</p>
<ul>
<li>为了缩小采样空间，作者先基于 $ x$ 和所有可能的<span class="math inline">\(\{y\}\)</span>构建了一个候选集 <span class="math inline">\(\mathbf Z_x\)</span>;</li>
<li>为了增加 <span class="math inline">\(K\)</span> 次采样 <span class="math inline">\(z\)</span> 的多样性, 作者增加了一些在 <span class="math inline">\(\mathbf Z_x\)</span> 聚类和判重的技巧；</li>
</ul>
<p>Reward function 被定义为了简单的 F1 score 来衡量每个生成的句子 <span class="math inline">\(\mathbf{\hat{y}}\)</span> 和 ground truth <span class="math inline">\(\mathbf y\)</span> 的 overlapping.</p>
<p>训练结束后，就可以用 <span class="math inline">\(p(z|x)\)</span> 概率 top-1000 的词作为候选集 <span class="math inline">\(\mathbf Z_x\)</span>, 然后再进行如上聚类和采样的过程，去生成多个responses.</p>
<h3 id="实验">实验</h3>
<p>实验数据就是用了微博和Twitter的数据，后面作者有公开源码和数据； Evaluation matrics用了 BLEU 和 Distinct-1/2, 其实感觉作者定义的 reward 函数就有点像 BLEU 这个metric…</p>
<blockquote>
<p>不太知道这样定义合不合适，因为BLEU，和作者定义的reward函数都是比较粗糙的去衡量生成文本的质量。这样就导致了这个问题有些强行拟合指标的嫌疑…</p>
</blockquote>
<h3 id="总结">总结</h3>
<p>这个问题很新，也比较切合实际，算是在挖一个很好的坑；</p>
<p>不过中间的一些过程可以尝试改进的地方应该还有很多，比如中间变量的设置，比如后面的reward函数</p>
<p>甚至，如果没有中间的离散变量，是不是也可以不用RL的方法去优化呢？</p>
<p>作者开放了源码：https://ai.tencent.com/ailab/nlp/dialogue.html</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/06/17/2018_2019/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Zhiyuan">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/Gold.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhiyuan">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/06/17/2018_2019/" itemprop="url">读博第一年（2018~2019）</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-06-17T16:46:22+08:00">
                2019-06-17
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/随感/" itemprop="url" rel="index">
                    <span itemprop="name">随感</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>其实意识到，很多事情都会随着成长而改变。</p>
<p>所以就想记录一下自己对各个问题当下的看法，也算是记录一些经历。</p>
<h2 id="读博学术">读博（学术）</h2>
<p>今年是2019， 去年的BERT一出来，原来那种改模型拼performance的想法慢慢的就佛了；</p>
<p>曾经想过一段时间如何去定位自己的工作；</p>
<p>后来渐渐的理解是，想要水论文，做一些有意思的新应用场景;</p>
<p>大厂，业界短期内不会商用的，或是现有阶段不适合，不支持业界部署的问题</p>
<p>像是做demo，绕开正面刚技术；</p>
<p>这种问题重在innovation, 如果好的想法做的完备，就比较适合通用的AI的刊和会去投；</p>
<p>至于NLP领域内，这类work的 contribution可能不会被大多做技术的认可。</p>
<h2 id="爱情">爱情</h2>
<p>目前的想法，其实没有什么精力去分给爱情…</p>
<p>感觉每天分给爱情的时间其实也就半个小时跟女票聊聊天</p>
<p>女票不粘人，我们各自都有很好的发展和规划，也远不到一起认真规划以后结婚生活的阶段</p>
<p>所以现在就是享受爱情</p>
<h2 id="金钱">金钱</h2>
<p>现阶段每个月会存下一些钱，但是也不是很多</p>
<p>买买港股小米的股票，或者定投就好了..</p>
<p>平时对生活质量的要求不算太高，有什么硬需求尽量满足就可以了</p>
<p>这一部分，没什么钱，也就没什么规划了</p>
<h2 id="人际关系">人际关系</h2>
<p>感觉学术里social其实还是个圈子的问题…</p>
<p>其实主动可以，我其实加了很多能接触到的NLP内比较厉害的人</p>
<p>但是更多的就是朋友圈点个赞</p>
<p>自己没有什么成果的，或者比较好的想法的话，空去谈合作，成功率可能不高</p>
<p>没人有义务带自己</p>
<p>所以我的理解就是先证明自己有能力发论文，然后再主动去谈合作吧…</p>
<p>不知道算不算拖延..</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/03/30/Text_style_transfer_papers/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Zhiyuan">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/Gold.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhiyuan">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/30/Text_style_transfer_papers/" itemprop="url">Text style transfer papers</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-03-30T17:17:30+08:00">
                2019-03-30
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Paper-notes/" itemprop="url" rel="index">
                    <span itemprop="name">Paper notes</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="text-style-transfer">Text style transfer</h2>
<p>总结一下，Text style transfer可以分为两个部分：</p>
<ol type="1">
<li>adverserial方法抽取semantic特征和style特征</li>
<li>如何生成特定style的句子</li>
</ol>
<p>模型，基本上都是VAE的天下。</p>
<p>存在的问题：</p>
<ol type="1">
<li>目前没有人给text style一个很清晰的定义</li>
<li>很难把semantic 特征和style特征分得开(一些词既可以表达semantic信息，同时也可以表达style信息)</li>
<li>特定的style 和 特定的semantic 的合成句子质量很难有很好的表现</li>
<li>没有suitable的 evaluation方法</li>
</ol>
<p><strong>语言是基于符号的，符号的规则又是有限的（又是离散符号</strong></p>
<p><strong>或许从更上一层，考虑到人在生成想要表达的语言的思维（或许是连续的），如何去拟合可能限制会更少，并且更加流畅</strong></p>
<h3 id="what-is-wrong-with-style-transfer-for-texts"><font color="green">What is wrong with style transfer for texts?</font></h3>
<p>主要介绍了一些目前text style transfer的问题，比较适合去找research gap.</p>
<ul>
<li>Text style 的定义不太清晰，无法准确建模</li>
<li>Adverserial net 的方法很难剥离 content 和 style</li>
</ul>
<h3 id="style-transfer-from-non-parallel-text-by-cross-alignmentnips-2017">Style Transfer from Non-Parallel Text by Cross-Alignment（NIPS 2017)</h3>
<p>重点在于非平行数据的分析； <strong>最印象深刻的是约束两个styles对应的content同分布</strong>； 同时，做法也是adverserial的方式分离content 和 style 然后再生成</p>
<h3 id="evaluating-style-modification-in-text">Evaluating Style Modification in Text</h3>
<p>一个Master的毕业论文吧。。 首先提到了一个 <strong>word mover’s distance on texts with style masked out 我觉得这个应用到我们的model里去找同样content的句子是一个很好的方式 （这个应该是一个保留了sequencial和content信息的相似度衡量）</strong></p>
<p>主要从这几个方面入手：</p>
<figure>
<img src="http://static.zybuluo.com/Preke/9t4yzetlwbmu8q3x2nds8lnv/image_1d76fo7fc1n5a1hl6gjnju9k57m.png" alt="Evaluating Style Modification in Text"><figcaption>Evaluating Style Modification in Text</figcaption>
</figure>
<p><strong>提到一个mask style words的方法去做content preserving</strong>； 这里可能可以用到去：</p>
<ul>
<li>训练auto-encoder</li>
<li>寻找对应sentence</li>
</ul>
<p>有个Wordnet的Style-lexicon</p>
<p>这几种度量方法可以借鉴</p>
<h3 id="style-transfer-in-text-exploration-and-evaluation">Style Transfer in Text: Exploration and Evaluation</h3>
<p>用对抗的方法去剥离style信息 from content信息</p>
<p>propose two novel evaluation metrics：</p>
<ul>
<li>transfer strength</li>
<li>content preservation</li>
</ul>
<h3 id="evaluating-prose-style-transfer-with-the-bible">Evaluating prose style transfer with the Bible</h3>
<p>主要是提供了一个Bible的Text style transfer的平行数据集</p>
<h3 id="a-monolingual-tree-based-translation-model-for-sentence-simplification">A Monolingual Tree-based Translation Model for Sentence Simplification</h3>
<p>简化句子，类似于text summerization, 和 style transfer的区别和联系呢？</p>
<p>利用传统方法（语法解析树）的方式去做</p>
<h3 id="generating-sentences-from-a-continuous-space"><font color="green">Generating Sentences from a Continuous Space</font></h3>
<p>本文讲的这个问题也是我比较感兴趣的一个问题： &gt; However, by breaking the model structure down into a series of next-step predictions, the rnnlm does not expose an interpretable representation of global features like topic or of high-level syntactic properties.</p>
<p>用VAE能够学到一个全局的特征like style， topic and high-level syntactic features 去解决imputing missing words(补全缺失词) 的问题</p>
<p>我觉得肯定是可以用到style-transfer里去抽取特征的</p>
<h3 id="multiple-attribute-text-rewriting"><font color="green">MULTIPLE-ATTRIBUTE TEXT REWRITING</font></h3>
<p>用back-translation的方法去掉style，看一下是怎么论述不需要分开style-attribute这个说法的</p>
<h3 id="toward-controlled-generation-of-text">Toward Controlled Generation of Text</h3>
<p>用VAE的方法去生成特定的sentiment 或者 tenses的句子</p>
<h3 id="unpaired-sentiment-to-sentiment-translation-a-cycled-reinforcement-learning-approach">Unpaired Sentiment-to-Sentiment Translation: A Cycled Reinforcement Learning Approach</h3>
<p>用强化学习的方法去转换情感 还是一个先remove词语，再去生成的一个方法</p>
<h3 id="adversarially-regularized-autoencoders">Adversarially Regularized Autoencoders</h3>
<p>VAE, CVAE, AAE, ARAE, DAE</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/03/27/Sentiment_analysis_papers/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Zhiyuan">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/Gold.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhiyuan">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/27/Sentiment_analysis_papers/" itemprop="url">Sentiment analysis papers</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-03-27T17:17:30+08:00">
                2019-03-27
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Paper-notes/" itemprop="url" rel="index">
                    <span itemprop="name">Paper notes</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="sentiment-analysis12-papers">Sentiment analysis（12 papers)</h2>
<p>直观感受是，但从sentiment这个角度讲</p>
<ul>
<li>单纯bag-of-words 目前已经不够了</li>
<li>Lexicons很重要</li>
<li>Word roles(POS)很重要</li>
<li>句法信息也很重要，但是不太好直接用</li>
<li>模型方面基本上baseline就是(Bi)LSTM+Attn了</li>
</ul>
<h3 id="sentiment-lexicon-enhanced-attention-based-lstm-for-sentiment-classification">Sentiment Lexicon Enhanced Attention-Based LSTM for Sentiment Classification</h3>
<p><font color="red">Current NN works 很少用到 Lexicons</font></p>
<p>Title 很好描述了本文工作</p>
<h3 id="a-multi-sentiment-resource-enhanced-attention-network-for-sentiment-classification">A Multi-sentiment-resource Enhanced Attention Network for Sentiment Classification</h3>
<p>Deep learning approaches for sentiment classification do not fully exploit <font color="red">sentiment linguistic knowledge.</font></p>
<ul>
<li>sentiment lexicon(此处有词干化，精细化处理）</li>
<li>negation words</li>
<li>intensity words</li>
</ul>
<p>sentiment resource 做 attention</p>
<h3 id="encoding-syntactic-knowledge-in-neural-networks-for-sentiment-classification">Encoding Syntactic Knowledge in Neural Networks for Sentiment Classification</h3>
<p>Rich <font color="red">syntactic knowledge</font> has not been fully explored when composing a longer text from its shorter constituent words</p>
<p>We discover that <strong>encoding syntactic knowledge (part-of-speech tag) in neural networks can enhance sentence/phrase representation</strong></p>
<p><code>tree-structured LSTM</code></p>
<p>其实出发点就是把句法信息加到模型中，这么说，其实语言也不单纯是一个sequencial的信息，但是为什么Tree-LSTM没有更加流行起来可能就是因为语法解析树太难了….不是目前大量跳AI坑的人说做就做的…</p>
<p>这个想法很有意思:</p>
<p><font color="red"><strong>We define sentiment-favorable representation as what is learned by a proper way of expressing sentiment, and is usually optimized with a sentiment-specific loss.</strong></font></p>
<h3 id="a-lexicon-based-supervised-attention-model-for-neural-sentiment-analysis">A Lexicon-Based Supervised Attention Model for Neural Sentiment Analysis</h3>
<p>Allows a recurrent neural network to <strong>focus on the sentiment content</strong>, thus generating <strong>sentiment-informative representations</strong>.</p>
<p>Sentiment degree based on sentiment lexicons (Attention 的权重）</p>
<h3 id="leveraging-multi-grained-sentiment-lexicon-information-for-neural-sequence-models">Leveraging Multi-grained Sentiment Lexicon Information for Neural Sequence Models</h3>
<p><strong>Multi-grained Sentiment Lexicon</strong> 多粒度级别Lexicons</p>
<p>The proposed method first <font color="red">encodes the fine-grained labels into sentiment embedding</font> and <font color="red">concatenates it with word embedding</font>.</p>
<figure>
<img src="http://static.zybuluo.com/Preke/9wma6ml3vpoglune4o3udj3n/image_1d6v2lakt12a69gtt1p1lr77l99.png" alt="image_1d6v2lakt12a69gtt1p1lr77l99.png-117.2kB"><figcaption>image_1d6v2lakt12a69gtt1p1lr77l99.png-117.2kB</figcaption>
</figure>
<p>这里说到表示程度的，否定词，都对分类有帮助。</p>
<p>提供了一个 Sentiment lexicon which contains:</p>
<ul>
<li>2759 positive words,</li>
<li>5111 negative words,</li>
<li>35 negation words and</li>
<li>62 intensifiers</li>
</ul>
<p>https://github.com/zengyan-97/Sentiment-Lexicon</p>
<h3 id="context-sensitive-lexicon-features-for-neural-sentiment-analysis"><font color="green">Context-Sensitive Lexicon Features for Neural Sentiment Analysis</font></h3>
<p>Most existing methods use sentiment lexicons without considering context, typically taking the count, sum of strength, or maximum sentiment scores over the whole input.(应该是一个比较重要的research gap)</p>
<p>Previous works:</p>
<ul>
<li>they do not explicitly handle semantic compositionality</li>
<li>they cannot effectively deal with word sense variations</li>
</ul>
<p>Model looks like:</p>
<figure>
<img src="http://static.zybuluo.com/Preke/u0zdwflmj1hpcqa2qxqocct3/image_1d6v3ll4hhk81mhkl1c1dat1ecb9.png" alt="image_1d6v3ll4hhk81mhkl1c1dat1ecb9.png-73.7kB"><figcaption>image_1d6v3ll4hhk81mhkl1c1dat1ecb9.png-73.7kB</figcaption>
</figure>
<h3 id="linguistically-regularized-lstm-for-sentiment-classification"><font color="green">Linguistically Regularized LSTM for Sentiment Classification</font></h3>
<p>在一个句子中不同的词，功能不同，对表征的贡献不同，本文是去find the role of the different kind of words.</p>
<p>Models are able to capture the <strong>linguistic role of sentiment words, negation words, and intensity words</strong> in sentiment expression.</p>
<p>our central idea is <font color="red">to regularize the difference between the predicted sentiment distribution of the current position, and that of the previous or next positions, in a sequence model</font>.</p>
<p>理解sentiment distribution? 和 style distribution 有何联系</p>
<h3 id="incorporating-lexicons-into-lstm-for-sentiment-classification">Incorporating Lexicons into LSTM for Sentiment Classification</h3>
<p>印鉴老师的paper.</p>
<p>也是考虑了词语在不同语境下的语义不同这个问题；</p>
<p>根本上也是在根据 word 的 role 去增加knowledge</p>
<p>Words in different part-of-speech correspond to different meanings, emotional polarity and score. The same word may have multiple meanings.</p>
<h3 id="imbalanced-text-sentiment-classification-using-universal-and-domain-specific-knowledge">Imbalanced text sentiment classification using universal and domain-specific knowledge</h3>
<p>考虑情感分析的两个问题：</p>
<ul>
<li>domain-sensitive</li>
<li>data imbalance</li>
</ul>
<p>Builds a <strong>domain-adaptive sentiment classification model</strong> that incorporates universal and domain-specific knowledge into a unified learning framework.</p>
<h3 id="saan-a-sentiment-aware-attention-network-for-sentiment-analysis">SAAN: A Sentiment-Aware Attention Network for Sentiment Analysis</h3>
<p>3步工作：</p>
<ul>
<li>a word-level mutual attention mechanism to model word-level correlation</li>
<li>a phrase-level convolutional attention is designed to obtain phrase-level correlation</li>
<li>a sentence-level multi-head attention mechanism is proposed to capture various sentimental information from different subspaces.</li>
</ul>
<h3 id="laan-a-linguistic-aware-attention-network-for-sentiment-analysis">LAAN: A Linguistic-Aware Attention Network for Sentiment Analysis</h3>
<p>同上文一样…</p>
<h3 id="attention-based-bilstm-network-with-lexical-feature-for-emotion-classification">Attention-Based BiLSTM Network with Lexical Feature for Emotion Classification</h3>
<p>Propose two simple models to fully learn the emotional features of the POS of words.</p>
<ol type="1">
<li>把每个词的POS-tag 和 LSTM 输出 拼在一起做 attention</li>
<li>分别用LSTM+attn 对 context 表示 和 POS标签（应该是做输入）学习，然后把最终特征拼一起</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/01/01/dialog_system/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Zhiyuan">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/Gold.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhiyuan">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/01/01/dialog_system/" itemprop="url">Dialog system记录</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-01-01T17:17:30+08:00">
                2019-01-01
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/工作记录/" itemprop="url" rel="index">
                    <span itemprop="name">工作记录</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="section">2019.1.1</h2>
<p>找了一个代码实现了一下seq2seq(GRU+attention)在一个小的task based的数据集（44M）上的结果 发现BLEU最高也只能到6，而用英法翻译数据（1.5g）一个epoch之后，BLEU就达到了13+（时间太长没有继续跑下去</p>
<p>生成的很多有包含thanks for your feedback类似的，就是有可能生成一些general的response，并不能直接应用到生产环境中。</p>
<p>分析来看(推测）：</p>
<ol type="1">
<li>数据量很小，不足以去训练seq2seq的model</li>
<li>task based可能还是更适合retrieval 的方法，generation的方法可能更适合free-talk</li>
</ol>
<p>code source: https://github.com/preke/FSE2019</p>
<h2 id="section-1">1.3</h2>
<p>昨晚和师兄讨论了一个domain adaption style transfer的idea; 师兄给了我一些已经写好的domain adaption的代码，然后结合这边原来写的seq2seq再完善一下，应该可以跑出来看看效果； 不过目前是要找到可以用的style transfer的数据集。</p>
<p>code source: https://github.com/preke/domain_adaption_style_transfer</p>
<h3 id="ref">ref:</h3>
<p>https://arxiv.org/abs/1804.06437 https://arxiv.org/pdf/1409.7495.pdf （目前参考这两个，但是应该会能够找到更多的一些paper在做这件事吧…）</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/11/14/EmoHERD/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Zhiyuan">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/Gold.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhiyuan">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/11/14/EmoHERD/" itemprop="url">Eliciting Positive Emotion through Affect-Sensitive Dialogue Response Generation A Neural Network Approach</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-11-14T17:17:30+08:00">
                2018-11-14
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Paper-notes/" itemprop="url" rel="index">
                    <span itemprop="name">Paper notes</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="abstract">Abstract</h2>
<ul>
<li><p>We build a fully data driven chat-oriented dialogue system that can dynamically mimic affective human interactions by utilizing a neural network architecture.</p></li>
<li><p>we propose a sequence-to-sequence response generator that <strong>considers the emotional context</strong> of the dialogue.</p></li>
<li><p>shows that incorporation of emotion into the training process helps reduce the perplexity of the generated responses,</p></li>
</ul>
<h2 id="model">Model</h2>
<ul>
<li>经典HERD</li>
</ul>
<figure>
<img src="http://static.zybuluo.com/Preke/r5an3or08it4vnq8btaamoy7/image_1cs8ufb1t1i1o17ep19m0162r11nqm.png" alt="HERD"><figcaption>HERD</figcaption>
</figure>
<p>(这个可以做多轮对话呀） <br></p>
<ul>
<li>Emo-HERD
<ul>
<li>Incorporate an <strong>emotion encoder</strong> into the HRED architecture</li>
<li>The emotion encoder is placed in the same hierarchy as the dialogue encoder, capturing emotion at dialogue-turn level and maintaining the emotion context history throughout the dialogue</li>
</ul></li>
</ul>
<figure>
<img src="http://static.zybuluo.com/Preke/nvbhd3dqvy32dot5ihytdz20/image_1cs8sg97q1ij3ts92kc1s8a15sv2t.png" alt="Emo-HERD"><figcaption>Emo-HERD</figcaption>
</figure>
<p>在对单轮对话生成 <span class="math inline">\(h_{dlg}\)</span> 之后，把 <span class="math inline">\(h_{dlg}\)</span> 输入到一个 emotion encoder中结合历史信息 <span class="math inline">\(h_{m-1}^{emo}\)</span> 生成emotion embedding <span class="math inline">\(h_{emo}\)</span></p>
<figure>
<img src="http://static.zybuluo.com/Preke/rr7tkqgcm4oid3taya7446e8/image_1cs8uknnk9h014du17h0825bcl13.png" alt="generate hemo"><figcaption>generate hemo</figcaption>
</figure>
<p>emotion encoder这里有自己的损失函数 <span class="math inline">\(cost_{emo}\)</span> 总的Emo-HERD的损失函数为: <img src="http://static.zybuluo.com/Preke/cazlc4pzfpab4iq08x1qn6dz/image_1cs8uvs1ni5qr501061v9t1q0f1g.png" alt="cost"></p>
<h2 id="metrics">Metrics:</h2>
<ul>
<li>perplexity</li>
<li>subjective evaluation to measure the <strong>naturalnes</strong>s and <strong>emotional impact</strong> of the generated responses</li>
</ul>
<h2 id="dataset">Dataset</h2>
<ul>
<li>SubTle, a large scale conversational corpus</li>
<li>Spontaneous affective conversational corpus</li>
<li>Constructing positive-emotion eliciting data</li>
</ul>
<h2 id="section"></h2>
<h2 id="acquisition">Acquisition：</h2>
<ul>
<li>utterance: Dialog中一轮对话中的一个<font color="red">(单方的?）</font> sentences (感觉从原文看是这样的）</li>
</ul>
<p>感觉有点蹭热点的嫌疑呀，14年的HERD, 加上了一个emotion encoder就发了… 反正帮助我理解HERD了吧…</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/11/14/slstm/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Zhiyuan">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/Gold.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhiyuan">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/11/14/slstm/" itemprop="url">A Syntactically Constrained Bidirectional-Asynchronous Approach for Emotional Conversation Generation</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-11-14T17:17:30+08:00">
                2018-11-14
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Paper-notes/" itemprop="url" rel="index">
                    <span itemprop="name">Paper notes</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="abstract">Abstract</h2>
<ul>
<li><p>poor logic and no emotion</p></li>
<li><p>a syntactically con- strained bidirectional-asynchronous approach for <code>emotional conversation generation</code> (E- SCBA) is proposed</p></li>
<li><p>In our model, pre-generated emotion keywords and topic keywords are asynchronously introduced into the process of decoding.</p></li>
</ul>
<h2 id="contribution">Contribution</h2>
<ol type="1">
<li>It conducts a study of compound information, which constitutes the syntactic constraint in the conversation generation.</li>
<li>A bidirectional-asynchronous decoder with multi-stage strategy is proposed to utilize the syntactic constraint.</li>
<li>Our experiments show that E-SCBA work better on emotion, logic and diversity than the general seq2seq and other models that consider only a sin- gle factor during the generation.</li>
</ol>
<h2 id="dataset">Dataset</h2>
<ul>
<li>Emotional conversation dataset NLPCC2017</li>
<li>1,119,201 Chinese post-reply pairs</li>
<li>randomly sampled 8,000 for validation, 3,000 for testing and the rest for training</li>
</ul>
<h2 id="model">Model</h2>
<figure>
<img src="http://static.zybuluo.com/Preke/57nvin5t51ekhs4b8mtfki27/image_1cs61nfsh165dh4c1ph8bjpjagp.png" alt="image_1cs61nfsh165dh4c1ph8bjpjagp.png-328.8kB"><figcaption>image_1cs61nfsh165dh4c1ph8bjpjagp.png-328.8kB</figcaption>
</figure>
<p>Keywords dictionary: 1. Emotion dictionary 2. Topic dictionary</p>
<ul>
<li>Step1: 输入Post, 得到topic keyword and emotion keyword
<ul>
<li>pretrained LDA 主题推断</li>
<li>emotion transfer network 得到emotion</li>
<li>(一些网络处理）得到topic keyword and emotion keyword that are expected to appear in the reply.</li>
</ul></li>
<li>Step2:
<ul>
<li>Post过LSTM(加入Emotion keyword), 得到一系列hidden vectors <span class="math inline">\(\{s_i^{et}\}\)</span><br>
</li>
<li>Post过LSTM(加入Topic keyword, Emotional attention), 得到一系列hidden vectors <span class="math inline">\(\{s_j^{tp}\}\)</span></li>
<li><font color="red">LSTM和Attention的常用结合方式？</font></li>
<li>用<span class="math inline">\(\{s_i^{et}\}\)</span> 去 attention <span class="math inline">\(\{s_j^{tp}\}\)</span> 得到 <strong>Middle Sequence(<span class="math inline">\(y^{md}\)</span>)</strong> (这里<span class="math inline">\(y^{md}\)</span> 不代表输出的words, 仅仅是中间变量而已）如图：get middle sequence</li>
<li>然后通过<span class="math inline">\(y^{md}\)</span> 得到 <span class="math inline">\(y^{ce}\)</span> 和 <span class="math inline">\(y^{ct}\)</span> 如图：get ce and ct <img src="http://static.zybuluo.com/Preke/4edy641z8lopisgm15bogwu5/image_1cs728vnp1bsp1743gko17mcn379.png" alt="get middle sequence"> <br></li>
</ul></li>
</ul>
<figure>
<img src="http://static.zybuluo.com/Preke/qt9plkibwr5fvzt7wzwncnvi/image_1cs72kfu14s0s3b15am52fv88m.png" alt="get ce and ct"><figcaption>get ce and ct</figcaption>
</figure>
<blockquote>
<p>提醒自己一点，LSTM每个输出也只是hidden states, 具体应用到decoder是还要加入一个选择当前输出词语的softmax:<span class="math inline">\(P(w_i|w_{i-1}, h_i, c_i)\)</span></p>
</blockquote>
<ul>
<li>Step3:<br>
concat 所有的东西 together: <span class="math inline">\(y^f=(y^{ct,b}, w_{tp}^k, y^{md,f}, w_{et}^k, y^{ce,f})\)</span> <span class="math inline">\(y^b\)</span> 就是 <span class="math inline">\(y^f\)</span> 的反向; And then 得到最终的hidden states 然后生成words:</li>
</ul>
<figure>
<img src="http://static.zybuluo.com/Preke/zptciuvc45fjyf2ffwj4ep1d/image_1cs739mit1j9lb0916ii3e7vvm9.png" alt="get hidden states"><figcaption>get hidden states</figcaption>
</figure>
<h2 id="experiment-and-metrics">Experiment and Metrics</h2>
<ul>
<li><strong>Embedding-based Metrics</strong>: We measure the similarity computed by <strong>cosine distance</strong> between a candidate reply and the target reply using <strong>sentence-level embedding</strong></li>
<li><strong>Distinct Metrics</strong>: By computing the number of different unigrams (Distinct-1) and bigrams (Distinct-2), we measure information and diversity in the candidate replies</li>
<li><strong>Human Annotations</strong></li>
</ul>
<h2 id="acquisition">Acquisition：</h2>
<p>方向的变换看不太懂，lstm的一些认识加深了一点</p>
<hr>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/11/14/ECM/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Zhiyuan">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/Gold.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhiyuan">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/11/14/ECM/" itemprop="url">Emotional Chatting Machine Emotional Conversation Generation with Internal and External Memory</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-11-14T17:17:30+08:00">
                2018-11-14
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Paper-notes/" itemprop="url" rel="index">
                    <span itemprop="name">Paper notes</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="abstract">Abstract</h2>
<p>In this paper, we propose Emotional Chatting Machine (ECM) that can generate appropriate responses not only in content (relevant and grammatical) but also in emotion (emotionally consistent).</p>
<p>ECM addresses the factor using three new mechanisms that respectively： - Models the high-level abstraction of emotion expressions by embedding emotion categories - Captures the change of implicit internal emotion states - Uses explicit emotion expressions with an <strong>external emotion vocabulary</strong></p>
<h2 id="contribution">Contribution</h2>
<ul>
<li>It proposes to address the <strong>emotion factor</strong> in large-scale conversation generation</li>
<li>It proposes an end-to-end framework (called ECM) to incorporate the emotion influence in large-scale conversation generation. It has three novel mechanisms: emotion category embedding, an internal emotion memory, and an external memory.</li>
<li>It shows that ECM can generate responses with higher content and emotion scores than the traditional seq2seq model.</li>
</ul>
<h2 id="problem">Problem:</h2>
<p>Given post $ X = [x_1,…x_n] $ and emotion factor <span class="math inline">\(e\)</span>, Output response <span class="math inline">\(Y = [y_1,...y_m]\)</span> coherent with the emotion <span class="math inline">\(e\)</span></p>
<p><span class="math display">\[
P(Y|X,e)= \prod_{i=1}^m(P(y_i|y_{&lt;i},X,e)
\]</span></p>
<h2 id="model">Model</h2>
<p><img src="http://static.zybuluo.com/Preke/3w8q9xm5wvlwbhfw133fpz7z/image_1csodth9h1ka6q9mcm7m3k1huf9.png" alt="ECM model"> 整体流程是： 先训练一个Emotion Classidier 来 annotate 训练数据的emotion; 然后将三元组(Post, response, target emotion)输入到ECM中，在decoder中结合target emotion的信息，依次生成每个word, (生成response) 然后再对response用同样的Emotion Classidier 做分类，得到response的情感来衡量效果</p>
<figure>
<img src="http://static.zybuluo.com/Preke/m8ewuvddl5icqvaw4wey1tqu/image_1csoduq9ah88e04f5m1qcso18m.png" alt="Internal Memory"><figcaption>Internal Memory</figcaption>
</figure>
<figure>
<img src="http://static.zybuluo.com/Preke/ded8bdig3g83wz5xe2w5a3di/image_1csodvkvn1af2b9n1r6c1mk51ilo13.png" alt="External Memory"><figcaption>External Memory</figcaption>
</figure>
<p>(中间的数学推断，看倒是看明白了，有点懒得誊一次…</p>
<h2 id="dataset">Dataset</h2>
<ul>
<li>NLPCC emotion classification dataset</li>
<li>STC conversation dataset *could found in the github: <a href="https://github.com/tuxchow/ecm" target="_blank" rel="noopener">source code</a></li>
</ul>
<h2 id="experiment-and-metrics">Experiment and Metrics</h2>
<ul>
<li>BLEU is not suitable for measuring conversation generation due to its low correlation with human judgment.</li>
<li>Perplexity(在读过的paper中最常见的）</li>
<li>Emotion accuracy</li>
</ul>
<figure>
<img src="http://static.zybuluo.com/Preke/0okuk2t5cip926nwjr4kokoa/image_1csoe3n91314cc21l9i16s8fom1g.png" alt="result1"><figcaption>result1</figcaption>
</figure>
<ul>
<li>Manual Evaluation</li>
</ul>
<h2 id="acquisition">Acquisition：</h2>
<p>过程感觉有点琐碎，细节上的修改和优化还是挺多的，不能说是一个很眼前一亮的工作吧（不是效果和问题不好，而是没那么直观），但是运行一下代码应该会有更加深的体会</p>
<hr>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/Gold.jpg" alt="Zhiyuan">
            
              <p class="site-author-name" itemprop="name">Zhiyuan</p>
              <p class="site-description motion-element" itemprop="description">三尺微命，一介书生</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">39</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">9</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">16</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/preke" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:geek00021@gmail.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://www.facebook.com/PrekeWen" target="_blank" title="FB Page">
                      
                        <i class="fa fa-fw fa-facebook"></i>FB Page</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://blog.csdn.net/u013398398" target="_blank" title="CSDN">
                      
                        <i class="fa fa-fw fa-home"></i>CSDN</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://www.jianshu.com/u/85555f21e657" target="_blank" title="简书">
                      
                        <i class="fa fa-fw fa-home"></i>简书</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://scholar.google.com.hk/citations?user=bLhErOwAAAAJ&hl=en" target="_blank" title="Google Scholar">
                      
                        <i class="fa fa-fw fa-graduation-cap"></i>Google Scholar</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://preke.github.io/cv/resume.html" target="_blank" title="Resume">
                      
                        <i class="fa fa-fw fa-user"></i>Resume</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Zhiyuan</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  
















  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config("");
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
  


  

  

</body>
</html>
